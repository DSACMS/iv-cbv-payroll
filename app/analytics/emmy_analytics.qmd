---
title: "EMMY Mixpanel Web Analytic Review"
date: now
date-format: "MMMM D, YYYY h:mm a"
language:
  title-block-published: "Last Updated"
execute:
  echo: false
  output: false
  warning: false
  #cache: true
format:
  html:
    toc: true
    number-sections: true
    css: dsac-theme.css
    embed-resources: true
  # docx:
  #   toc: true
  #   number-sections: true
  #   reference-doc: custom-reference-doc.docx
  #   highlight-style: github
  #   dpi: 300
---

# Overview

## Purpose

Over the past year, the Centers for Medicare and Medicaid Services (CMS) in conjunction with partner states have piloted an online income verification application, Eligibility Made Easy (EMMY). With each phase, analysts have explore the web analytics data, looking into applicant uptake and utilization of the tool. This specific report aims identify areas of the tool where retention drops in an effort to improve the product design, making it easier for applicants to complete the full form.

## Key Takaways

1.  Significant drop-off rate threatens progress success.
    -   Issue - a substantial portion of applicants are starting but not completing the income verification process
    -   Why it matters - this limits the program's ability to help eligible beneficiaries access Medicaid benefits
2.  The employer search functionality is a critical bottleneck
    -   Issue - about 19% of employer searches return "missing" results across all three
        pilot periods (May, Aug, Nov 2025), with 34% of applicants dropping off
        at this step in November
    -   Why it matters - a major roadblock preventing eligible applicants from completing verification
3.  Help documentation usage patterns suggest possible UX confusion
    -   Issue - Applicants who completed the application had slightly more "help
        actions" than those who didn't, with significantly higher help usage on
        the agreement page among those who dropped off
    -   Why it matters - The agreement page may be confusing or concerning to users, causing them to seek help and then possibly abandon the process
4.  Seeing a higher completion rate for those starting from a mailed link
    -   Issue - Completion rates are low and while we are seeing a rise in completion rates for those accessing via mailed link, completion from SMS messages remains static
    -   Why it matters - The app is designed to be mobile-friendly, so understanding
        device-based completion rates is critical for optimizing the user
        experience
5.  Multi-session users investigation
    1.  Issue - More than half of users in November have two or more sessions (whether they are completing or not)
    2.  Why it matters - Need to understand the factors leading to this in order to possibly improve information or UX as well as think about feature such as possibly ensuring state persistence across sessions

## Method

This report was generated using a Quarto notebook and leverage R for all analysis and visualizations. The analysis focuses on the 2025 Lousiana pilot, which had three, 6-week session starting May, August, and November. The web analytics data come from Mixpanel, accessed using python for the API call with a [Jupyter Notebook](https://github.com/DSACMS/iv-cbv-payroll/blob/main/app/analytics/analytics.ipynb). All of the underlying code can be found on [GitHub](https://github.com/DSACMS/iv-cbv-payroll/tree/main/app/analytics).

## Defintions/Calculations

Its easy to construct similar metrics in different ways and yield slightly different results. For tranparency, below are some definitions to key concepts or calculations

-   **Applicant**: uses the `distinct_id` associated with the event.
-   **Session**: relies on the `properties$cbv_flow_id`. A applicant may have one or more sessions during a pilot period.
-   **Total Event**: When an applicant has multiple sessions, each of these unique applicant and sessions is called an total event in Mixpanel.
-   **Application submitted/successful**: the applicant finished the submission flow ending on the success page (`event == 'ApplicantSharedIncomeSummary'`).
-   **Application start time**: uses the `timestamp` the applicant viewed the agreement page (`event == 'ApplicantViewedAgreement'`)
-   **Application duration**: the duration is then calculated from the difference between the session start time and the `timestamp` the last event was viewed.
-   **Provider sync time**: calculated using the `timestamp` between two events, `ApplicantSucceededWithLogin` and `ApplicantFinishedSync`

## Limitations/Notes

-   Not all applicants are accessing from tokenized links (or each time) and therefore we can't track repeated users from generic links
-   Demographic and other characteristics are only available from the event that syncs with Argyle/Pinwheel
-   Multiple events can be triggered at the exact same time

# Analysis

```{r}
#| label: dependencies

#dependencies to load
library(tidyverse)
library(here)
library(arrow, warn.conflicts = FALSE)
library(jsonlite, warn.conflicts = FALSE)
library(glue)
library(patchwork)
library(scales)
library(gt)
library(ggtext)
library(ggsankey) ## remotes::install_github("davidsjoberg/ggsankey")
library(ggbump) ## remotes::install_github("davidsjoberg/ggbump")
library(glamr) ##install.packages('glamr', repos = c('https://usaid-oha-si.r-universe.dev', 'https://cloud.r-project.org'))
library(glitr) #install.packages('glitr', repos = c('https://usaid-oha-si.r-universe.dev', 'https://cloud.r-project.org'))
library(gtayblr) ## remotes::install_github("USAID-OHA-SI/gtayblr")
```

```{r}
#| label: global variables
#| echo: false
#| warning: false

#identify paths for json data for each of the three periods
mp_path <- list.files(here("app/analytics"), "mixpanel.*parquet", full.names = TRUE)

#default viz/table caption
default_caption <- "Source: Lousiana 2025 EMMY Pilot Mixpanel Data [accessed 2025-12-15]"

#set DSAC colors
dsac_color <- c("#103D68", "#136A5D", "#6A1344", "#EFAC2F", "#63789D", "#C1C9D7", "#5A9088", "#D9E8E5", "#842F66", "#123054")
dsac_color_name <- c("navy", "teal", "cranberry", "gold", "light_navy", "pale_navy", "light_teal", "pale_teal", "light_cranberry", "dark_navy")
dsac_color <- setNames(dsac_color, dsac_color_name)
rm(dsac_color_name)
```

```{r}
#| label: import_data

df_mp <- read_parquet(mp_path)
```

```{r}
#| label: latest_pilot

latest_pilot <- levels(df_mp$pilot) |> tail(n=1)

```

```{r}
#| label: fcn_clean_events

#clean event names for viz to add space and remove repetitive "applicant" text
clean_events <- function(df){

  df |> 
    mutate(
      event_clean = event |> 
        str_replace_all("(?<!^)([A-Z])", " \\1") |> 
        str_remove("Applicant ") |> 
        str_remove(" Or Platform Item") |> 
        str_replace("M F A", "MFA") |> 
        str_replace("C B V", "CBV"),
        .after = event
        )
}
```

## How many applicants are starting but not completing the process?

To start off with, we need to understand how many applicants are starting out this process. The table below looks at both applicants and events. The events are the total number of times a page was accessed and the applicants are the count of distinct applicant. The first pilot in May did not have the same means of determining unique applicants, so the table below only reports the total events for the May pilot. November saw an increase in the number of applicants start the process (i.e. viewed the agreement), but when comparing the completion rate by applicants and events, the rate has remained relatively constant throughout.

```{r}
#| label: retention_tbl
#| output: true

 df_compl_pilot <- df_mp |> 
  filter(event %in% c("ApplicantViewedAgreement","ApplicantSharedIncomeSummary")) |> 
  clean_events() |> 
  group_by(pilot, event_clean) |> 
  summarise(
    applicants = n_distinct(distinct_id),
    events = n(),
    .groups = "drop"
    ) |>
  pivot_longer(c(applicants, events), names_to = "denom") |> 
  pivot_wider(
    names_from = event_clean,
    values_from = value
    ) |> 
  mutate(`Completion Rate` = `Shared Income Summary` / `Viewed Agreement`) |> 
  mutate(across(where(is.numeric), ~ ifelse(pilot == "May 2025" & denom == "applicants", NA_integer_, .x)))

df_compl_pilot |> 
  gt(groupname_col = "denom") |> 
  cols_move(`Viewed Agreement`, after = pilot) |> 
  format_numeric_columns() |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  adjust_row_padding() |> 
  add_labs(
    title = "STEADY COMPLETION RATE IN ALL PILOTS",
    subtitle = "The distinct number of applicants who started and completed the process",
    caption = md(glue("Note: The May pilot did not capture unique applicants, so only total events is reported. <br>
    {default_caption}"))
  ) |> 
    sub_missing()

```

```{r}
#| label: multi_complete

df_success_diff <- df_mp |> 
  filter(
    event %in% c("ApplicantSharedIncomeSummary"),
    pilot == "Nov 2025"
    ) |> 
  group_by(pilot) |>
  summarize(
    applicants = n_distinct(distinct_id),
    sessions = n_distinct(distinct_id, cbv_flow_id),
    .groups = 'drop'
  )
```

There are a number of applicants who had multiple successful submissions (across multiple sessions, which). In the November pilot, for example, there were `{r} scales::label_comma()(df_success_diff$applicants)` distinct applicants who submitted compared with `{r} scales::label_comma()(df_success_diff$sessions)` total events.

```{r}
#| label: multi_complete_tbl_calc

df_multi_tbl <- df_mp |> 
  filter(event %in% c("ApplicantSharedIncomeSummary")) |> 
  distinct(pilot, distinct_id, cbv_flow_id) |> 
  count(pilot, distinct_id, sort = TRUE, name = "submissions") |> 
  count(pilot, submissions, name = "applicants") |> 
  arrange(submissions) |> 
  group_by(pilot) |> 
  mutate(
    `Total Applicants` = sum(applicants),
    `Total Events` = sum(submissions*applicants)) |> 
  ungroup() 

#November data for text
df_multi_tbl_nov <- df_multi_tbl |> 
  filter(pilot == "Nov 2025")
```

The table below details how many submissions were associated with an applicant.[^1] In the November case, there were `r sum(df_multi_tbl_nov[df_multi_tbl_nov$submissions > 1, ]$applicants)` applicants who submitted more than one time; most of those multi-submission applicants, `r sum(df_multi_tbl_nov[df_multi_tbl_nov$submissions == 2, ]$applicants)`, submitted their applicants twice.

[^1]: Since not all applicants are using tokenized link, there may in fact be more applicants successfully submitting multiple times

```{r}
#| label: multi_complete_tbl
#| output: true
#| 
df_multi_tbl |> 
  pivot_wider(names_from = submissions, values_from = applicants) |> 
  gt() |>
  format_numeric_columns() |> 
  sub_missing() |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  tab_spanner(
    label = "# of submissions",
    columns = -c(pilot, `Total Applicants`, `Total Events`)
  ) |> 
  adjust_row_padding() |> 
  add_labs(
    title = "Some applicants had multiple successful submissions events" |> toupper(),
    subtitle = "the number of successful submission",
    caption = glue("Note: total sessions is the number of unique applicants and  {default_caption}")
  ) 
```

```{r}
#| label: multi_compl_deep_dive

#identify which applicants submitted multiple income summaries
v_multi <- df_mp |> 
  filter(pilot == "Nov 2025") |> 
  filter(event %in% c("ApplicantSharedIncomeSummary")) |> 
  distinct(pilot, distinct_id, cbv_flow_id) |> 
  group_by(distinct_id) |> 
  filter(n() > 1) |> 
  ungroup() |> 
  distinct(distinct_id) |> 
  pull()

#pull the employer information from their sync
df_multi <- df_mp |> 
  filter(
    pilot == "Nov 2025",
    event %in% c("ApplicantFinishedSync"),
    distinct_id %in% v_multi
  ) |> 
  select(pilot, distinct_id, cbv_flow_id, employer_name)

#review entries
df_mult_types <- df_multi |> 
  add_count(distinct_id, employer_name, name = "submission_count") |> 
  group_by(distinct_id) |> 
  summarise(
    unique_sessions = n_distinct(distinct_id, cbv_flow_id),
    unique_events = n(),
    unique_employers = n_distinct(employer_name),
    max_repeats = max(submission_count), 
    .groups = "drop"
  ) |> 
  mutate(
    behavior = case_when(
      unique_employers == 1 ~ "Single item repeated",
      unique_employers == unique_events ~ "All unique items",
      max_repeats > 1 ~ "Multiple items with repeats",
      TRUE ~ "Other"
    )
  ) 
  
  # df_multi |> 
  #   left_join(df_mult_types |> select(distinct_id, behavior)) |> 
  #   write_csv(here("app/analytics/multi_sub.csv"))

  df_mult_types <- df_mult_types |> 
    count(behavior)

```

We should take a closer look at the repeated submissions. Some of these could be resubmissions of the same information (i.e. the applicant didn't know if the submission went through or forgot they already submitted it) or could be going back to enter in a different employer at a different time. If we look at the `r sum(df_mult_types$n)` applicants with repeated submissions in the November pilot, `r df_mult_types[df_mult_types$behavior == 'Single item repeated',]$n` submitted for the same employer each time, `r df_mult_types[df_mult_types$behavior == 'Multiple items with repeats',]$n` submitted different employers (some with repeats), and only `r df_mult_types[df_mult_types$behavior == 'All unique items',]$n` had all unique employer submissions. The table below provides some examples of how the different behaviors might look like in the data.

```{r}
#| label: multi_examples
#| output: true

tribble(
  ~Applicant, ~Session,               ~Employer,                     ~Behavior,
         "A",       "001",                "Z-Mart",        "Single item repeated",
         "A",       "002",                "Z-Mart",        "Single item repeated",
         "B",       "001",              "Acme Inc",        "Single item repeated",
         "B",       "002",              "Acme Inc",        "Single item repeated",
         "B",       "003",              "Acme Inc",        "Single item repeated",
         "B",       "004",              "Acme Inc",        "Single item repeated",
         "C",       "001",            "Work Depot", "Multiple items with repeats",
         "C",       "002",       "Blue's Pharmacy", "Multiple items with repeats",
         "C",       "003",            "Work Depot", "Multiple items with repeats",
         "C",       "003",       "Blue's Pharmacy", "Multiple items with repeats",
         "D",       "001",      "Total Hair Works", "Multiple items with repeats",
         "D",       "002",        "Nails and More", "Multiple items with repeats",
         "D",       "002",      "Total Hair Works", "Multiple items with repeats",
         "E",       "001",           "Movie Store",            "All unique items",
         "E",       "002", "Paint Supplies & More",            "All unique items"
) |> 
  gt(groupname_col = "Behavior") |> 
  adjust_row_padding() |> 
  si_gt_base(header_fill = dsac_color['light_teal'])

```

### Is there a drop in completion as the pilot period draws on?

If we compare weeks with in each pilot, we are seeing a similar trend of most people starting in the first week or two and then tailing off after that. While the first two pilot periods saw the second week as having the highest completion rate, the current pilot saw an increase in weeks 2 and then week 3 for completion rates.

```{r}
#| label: retention_viz
#| output: true

 df_compl_wkly <- df_mp |> 
  filter(event %in% c("ApplicantViewedAgreement","ApplicantSharedIncomeSummary")) |> 
  clean_events() |> 
  mutate(week = timestamp |> floor_date("weeks") |> as_date()) |> 
  group_by(pilot, week, event_clean) |> 
  summarise(
    applicants = n_distinct(distinct_id),
    events = n(),
    .groups = "drop"
    ) |>
  pivot_longer(c(applicants, events), names_to = "denom") |> 
  pivot_wider(
    names_from = event_clean,
    values_from = value
    ) |> 
  mutate(
    completion_rate_wk = `Shared Income Summary` / `Viewed Agreement`,
    across(where(is.numeric), ~ ifelse(pilot == "May 2025" & denom == "applicants", NA_integer_, .x))
    ) |> 
  group_by(pilot) |> 
  mutate(plt_wk = glue("wk{isoweek(week) - min(isoweek(week)) + 1}"), .after = pilot) |> 
  ungroup()


# merge on pilot average rate for viz
df_compl_wkly <- df_compl_wkly |> 
  left_join(
    df_compl_pilot |> 
      select(pilot, denom, completion_rate_pilot = `Completion Rate`) |> 
      mutate(plt_wk = 'wk5'),
    by = join_by(pilot, plt_wk, denom)
    )

v1 <- df_compl_wkly |> 
  arrange(plt_wk, desc(denom)) |> 
  ggplot(aes(plt_wk, `Viewed Agreement`, fill = denom)) +
  geom_col(position = position_dodge(-.5), na.rm = TRUE) + 
  facet_grid(~pilot, scales = "free_x", space = "free_x", switch = "y") +
  scale_y_continuous(label = label_comma(scale_cut = cut_short_scale()), breaks = seq(0, 14000, 2000)) +
  scale_fill_manual(values = c(applicants = unname(dsac_color['light_navy']), events = unname(dsac_color['pale_navy']))) +
  si_style_ygrid() +
  labs(
    x = NULL, y = NULL,
    subtitle = glue("Started Application (<span style = color:{dsac_color['light_navy']};>**applicants**</span>/<span style = color:{dsac_color['pale_navy']};>**events**</span>)")) +
  theme(
    strip.text = element_text(hjust = .5),
    strip.placement = "outside",
    panel.spacing = unit(0.5, "lines"),
    legend.position = "none",
    plot.subtitle = element_markdown(),
    )

  v2 <- df_compl_wkly |> 
  ggplot(aes(plt_wk, completion_rate_wk, fill = denom)) +
  geom_col(na.rm = TRUE) +
  geom_hline(
    aes(yintercept = completion_rate_pilot), na.rm = TRUE,
    color = dsac_color[['cranberry']],
    linetype = "dashed"
    ) +
  geom_label(
    aes(
      y = completion_rate_pilot,
      label = label_percent(1)(completion_rate_pilot)), 
    na.rm = TRUE, fill = "white",
    family = "Source Sans 3", color = matterhorn, linewidth = 0,
    ) +
  facet_grid(fct_rev(denom) ~pilot, scales = "free_x", , space = "free_x", switch = "y") +
  scale_y_continuous(label = label_percent()) +
  scale_fill_manual(values = c("events" = "#97b2ae", 'applicants' = unname(dsac_color[['light_teal']]))) + 
  labs(
    x = NULL, y = NULL,
    subtitle = "Application Completion Rate") +
  si_style_ygrid() +
  theme(
    strip.text.y = element_text(hjust = .5, face = "bold"),
    strip.text.x = element_text(hjust = .5),
    strip.placement = "outside",
    panel.spacing = unit(0.5, "lines"),
    legend.position = "none"
    )

    v1 / v2 + 
      plot_annotation(
        title = "LARGE DROP OFF IN INITIATING APPLICATION AFTER THE FIRST WEEK, BUT LARGER COMPLETION RATE IN FOLLOWING WEEKS" |> str_wrap(70),
        caption = glue("Note: The May pilot did not capture unique applicants, so only total events is reported.
    {default_caption}"),
        theme = si_style()
      )
```

### Is there a difference in completion based on their device or how they receive the pilot link?

For the Louisana pilot, applicants were sent both text messages and emailed/mailed with a notice about the pilot. We can investigate whether there is any difference in completion rates based on how the applicants are accessing the app.

```{r}
#| label: device_origin_status

#flag if the applicant started on a tokenized or generic link
df_device_origin_status <- df_mp |> 
  mutate(
    initiation = case_when(event %in% c("ApplicantClickedCBVInvitationLink", "ApplicantClickedGenericLink") ~ str_extract(event, "CBVInvitation|ClickedGenericLink")),
    initiation = initiation |> 
      str_replace_all("(?<!^)([A-Z])", " \\1") |> 
      str_remove('C B V ')
  ) 

#fill missing across flow - initiation, device, and origin
df_device_origin_status <- df_device_origin_status |> 
  group_by(distinct_id, cbv_flow_id) |> 
  fill(device_type, origin, initiation, .direction = "updown") |> 
  ungroup() 

#create completion variable
df_device_origin_status <- df_device_origin_status |> 
  filter(event %in% c("ApplicantViewedAgreement", "ApplicantSharedIncomeSummary")) |> 
  mutate(
    started = event == "ApplicantViewedAgreement",
    completed = event == "ApplicantSharedIncomeSummary",
    ) 

#clean up columns for viz
df_device_origin_status <- df_device_origin_status |>
  mutate(
    across(c(device_type, origin, initiation), ~ ifelse(is.na(.), "unknown", .)),
    device_type = ifelse(device_type %in% c("desktop", 'smartphone', 'unknown'), device_type, "other"))

#aggregate to flow level
df_device_origin_status <-df_device_origin_status |> 
  group_by(pilot, distinct_id, cbv_flow_id, device_type, origin, initiation) |> 
  summarise(
    across(c(started, completed), ~ sum(.x, na.rm = TRUE)), 
    .groups = "drop"
    )

#address for device duplicate flows
df_device_origin_status <-df_device_origin_status |> 
  group_by(cbv_flow_id) |>
  mutate(device_type = ifelse(n() > 1, "multiple", device_type)) |> 
  ungroup()

#other device types
other_devices <- unique(df_mp$device_type) |> 
  str_subset("desktop|smartphone", negate = TRUE) |> 
  paste0('s') |> 
  glue_collapse(sep = ', ', last = ", and ")

```

When comparing the device type, we can see there is a preference for applicants initiating the process on their phones. The success rate has been higher on the phones than desktop, but both success rates are rather low. Interestly there has been a drop each pilot in desktop completion rates and in November, there was actual a gain in smartphone completion rate, futhering the divide. The other types of devices include `{r} other_devices`. Each pilot also see a number of unknown devices. Looking at the sessions for these unknown devices, they almost exclusively are just clicking the link to start and viewing the agreement page and not going beyond that.

```{r}
#| label: device_status_viz
#| output: true

df_device_status_viz <- df_device_origin_status |>
  group_by(pilot, device_type) |> 
  summarise(
    started = sum(started, na.rm = TRUE),
    completion_rate = sum(completed, na.rm = TRUE) / n(),
    .groups = "drop"
  ) |> 
    pivot_longer(
      c(started, completion_rate),
      names_to = "type"
    ) |> 
  mutate(
    value_label = ifelse(type == "started", label_comma(1)(value), label_percent(1)(value)),
    fill_color = ifelse(type == "started", dsac_color["light_navy"], dsac_color["light_teal"]),
    type = ifelse(type == "started", "Started Application", "Completion Rate")
    )

df_device_status_viz |> 
  ggplot(aes(value, fct_reorder(device_type, value, sum), fill = fill_color)) +
  geom_col() +
  geom_text(aes(label = value_label), family = "Source Sans 3", color = matterhorn, hjust = -.1) +
  facet_grid(pilot~fct_rev(type), scales = "free", space = "free_y", switch = "y") +
  coord_cartesian(clip = "off") +
  scale_fill_identity() +
  si_style_xgrid() +
  labs(
    x = NULL, y = NULL,
    title = "MOST APPLICANTS START AND HAVE A HIGHER COMPLETION RATE ON A SMARTPHONE THAN DESKTOP" |> str_wrap(70),
    subtitle = "number of events by device type",
    caption = glue("Note: Other devices include {other_devices}
    {default_caption}")
  ) +
  theme(
    legend.position = "none",
    axis.text.x = element_blank(),
    strip.placement = "outside",
    panel.spacing.x = unit(1.5, "lines"),
    panel.spacing.y = unit(0.5, "lines"),
    strip.text.y = element_text(hjust = .5)
  )

```

When looking the link/url origin, we see the large majority arise from SMS messages. However, the success rate is much lower than that of physical mailings. The November pilot introduced the ability to share the link with a household member on the final stage; `r nrow(df_device_origin_status[df_device_origin_status$origin == "shared",])` sessions were started with this shared link.

```{r}
#| label: origin_status_viz
#| output: true

df_origin_status_viz <- df_device_origin_status |>
  group_by(pilot, origin) |> 
  summarise(
    started = n(),
    #completed = sum(completed, na.rm = TRUE),
    completion_rate = sum(completed, na.rm = TRUE) / n(),
    .groups = "drop"
  ) |> 
    pivot_longer(
      c(started, completion_rate),
      names_to = "type"
    ) |> 
  mutate(
    value_label = ifelse(type == "started", label_comma(1)(value), label_percent(1)(value)),
    fill_color = ifelse(type == "started", dsac_color["light_navy"], dsac_color["light_teal"]),
    type = ifelse(type == "started", "Started Application", "Completion Rate"),
    origin = str_replace(origin, "mfb_", "MFB ")
    )

df_origin_status_viz |> 
  filter(pilot != "May 2025") |> 
  ggplot(aes(value, fct_reorder(origin, value, sum), fill = fill_color)) +
  geom_col() +
  geom_text(aes(label = value_label), family = "Source Sans 3", color = matterhorn, hjust = -.1) +
  facet_grid(pilot~fct_rev(type), scales = "free", space = "free_y", switch = "y") +
  coord_cartesian(clip = "off") +
  scale_fill_identity() +
  si_style_xgrid() +
  labs(
    x = NULL, y = NULL,
    title = "Mailed links had the highest flow completion rate" |> toupper(),
    subtitle = "number of distinct flows by url link origin",
    caption = glue("Note: Excludes May pilot which did not capture origin
    {default_caption}")
  ) +
  theme(
    legend.position = "none",
    axis.text.x = element_blank(),
    strip.placement = "outside",
    panel.spacing.y = unit(0.5, "lines"),
    panel.spacing.x = unit(1.5, "lines"),
    strip.text.y = element_text(hjust = .5)
  )
```

Lastly, we can take a look at how the applicant started their session. In the November pilot, tokenized invitations where shared for the first time (as opposed to only generic links). More applicants started the process with a invitation link, but the these sessions were less than half as successful in completing the process as the generic link. This is the opposite of what occurred in the August pilot.

```{r}
#| label: tokenized_status
#| output: true

df_link_status_viz <- df_device_origin_status |>
  filter(!pilot %in% c("May 2025", "Aug 2025")) |> 
  group_by(pilot, initiation) |> 
  summarise(
    started = n(),
    completion_rate = sum(completed, na.rm = TRUE) / n(),
    .groups = "drop"
  ) |> 
    pivot_longer(
      c(started, completion_rate),
      names_to = "type"
    ) |> 
  mutate(
    value_label = ifelse(type == "started", label_comma(1)(value), label_percent(1)(value)),
    fill_color = ifelse(type == "started", dsac_color["light_navy"], dsac_color["light_teal"]),
    type = ifelse(type == "started", "Started Application", "Completion Rate")
    )

df_link_status_viz |> 
  ggplot(aes(value, fct_reorder(initiation, value, sum), fill = fill_color)) +
  geom_col() +
  geom_text(aes(label = value_label), family = "Source Sans 3", color = matterhorn, hjust = -.1) +
  facet_grid(pilot~fct_rev(type), scales = "free", space = "free_y", switch = "y") +
  coord_cartesian(clip = "off") +
  scale_fill_identity() +
  si_style_xgrid() +
  labs(
    x = NULL, y = NULL,
   title = "GENERIC LINK SESSIONS SAW A LARGER SUCCESS RATE IN NOVEMBER"|> str_wrap(70),
    subtitle = "number of distinct flows by initiation type",
    caption = default_caption
  ) +
  theme(
    legend.position = "none",
    axis.text.x = element_blank(),
    strip.placement = "outside",
    panel.spacing.x = unit(1.5, "lines"),
    panel.spacing.y = unit(0.5, "lines"),
    strip.text.y = element_text(hjust = .5)
  )
```

## How long does it take to complete the application?

On the client side, the goal of the pilot application is to creating something easy to complete. Ideally, applicants can complete the process in a matter of minutes. We can look at time it takes to submit to understand if it places an undue burden on applicants.

```{r}
#| label: duration_calc

df_time <- df_mp |> 
  filter(str_starts(distinct_id, "applicant")) |> 
  mutate(
    completed = event == "ApplicantSharedIncomeSummary", 
    time_start = case_when(event == "ApplicantViewedAgreement" ~ timestamp)
    ) |> 
  group_by(pilot, distinct_id) |> 
  # group_by(pilot, distinct_id, cbv_flow_id) |> 
  mutate(
    completed = max(completed, na.rm = TRUE),
    time_end = ifelse(event == "ApplicantSharedIncomeSummary", timestamp, max(timestamp)),
    time_end = as_datetime(time_end)
    ) |>
  ungroup()

df_duration <- df_time |> 
  filter(!is.na(time_start)) |> 
  group_by(pilot, distinct_id) |> 
  summarise(
    # sessions = n_distinct(cbv_flow_id),
    completed = max(completed, na.rm = TRUE),
    time_start = max(time_start, na.rm = TRUE),
    time_end = max(time_end, na.rm = TRUE),
    .groups = "drop"
    ) |> 
  # tidylog::filter(time_start != time_end) |> 
  mutate(duration = time_end - time_start)
```

```{r}
#| label: duration_stats

df_duration_viz <- df_duration |> 
  mutate(
    completed_type = case_when(
      completed == 1 ~ 'completed',
      time_start == time_end ~ 'just clicked',
      TRUE ~ 'incomplete'
      ),
    minutes = as.numeric(duration) / 60  
      ) |> 
  group_by(pilot, completed_type) |> 
  summarise(
    n = n(),
    q25 = quantile(minutes, 0.25, na.rm = TRUE),
    median = median(minutes, na.rm = TRUE),
    mean = mean(minutes, na.rm = TRUE),
    q75 = quantile(minutes, 0.75, na.rm = TRUE),
    q90 = quantile(minutes, .9, na.rm = TRUE),
    .groups = "drop"
    ) |> 
    mutate(
      fill_color = 
        case_match(completed_type,
        'completed' ~ dsac_color['light_navy'],
        'incomplete' ~ dsac_color['light_cranberry'],
        'just clicked' ~ dsac_color['light_cranberry']
        ),
      completed_type_lab = glue('{completed_type} (n = {label_comma()(n)})')
    )

  df_duration_stats <- df_duration_viz |> 
    filter(pilot == 'Nov 2025')
```

Looking specifically at the November pilot, of the `{r} scales::label_comma()(df_duration_stats[df_duration_stats$completed_type == 'completed',]$n)` applicants who completed the application, the median time was `{r} scales::label_number(.1)(df_duration_stats[df_duration_stats$completed_type == 'completed',]$median)` minutes, with 75% completing it within `{r} scales::label_number(.1)(df_duration_stats[df_duration_stats$completed_type == 'completed',]$q75)` minutes. The timing looks pretty good from that vantage point. However, most applicants (`{r} scales::label_comma()(df_duration_stats[df_duration_stats$completed_type != 'completed',]$n |> sum())`) are not completing the application. Of those applicants, `{r} scales::label_percent()(df_duration_stats[df_duration_stats$completed_type == 'just clicked',]$n / df_duration_stats[df_duration_stats$completed_type != 'completed',]$n |> sum())` are clicking the link and not proceeding beyond viewing the initial agreement page. When looking at incomplete applications excluding those that only viewed the agreement page, the median applicant spends `{r} scales::label_number(.1)(df_duration_stats[df_duration_stats$completed_type == 'incomplete',]$median)` minutes on the application before they stop, with 75% aborting after only `{r} scales::label_number(.1)(df_duration_stats[df_duration_stats$completed_type == 'incomplete',]$q75)` minutes.

```{r}
#| label: viz_duration
#| output: true
df_duration_viz |>  
  ggplot(aes(y = fct_rev(completed_type_lab), group = completed_type, color = fill_color)) +
  geom_linerange(aes(xmin = q25, xmax = q75)) +
  geom_point(aes(median), size = 4) +
  geom_text(
  data  = df_duration_viz |> filter(median != 0),
    aes(median, label = label_number(accuracy = .1, suffix = 'm')(median)), 
    family = "Source Sans 3", vjust = -1) +
  facet_grid(pilot ~. , switch = "y", scales = "free_y") +
  scale_x_continuous(labels = label_number( suffix = 'm'), position = "top") +
  scale_color_identity() +
  coord_cartesian(clip = "off") +
  labs(
    x = NULL, y = NULL,
    title = glue("{toupper(df_duration_stats$pilot[1])} INCOMPLETE APPLICATIONS END AFTER ABOUT {label_number(.1)(df_duration_stats[df_duration_stats$completed_type == 'incomplete',]$median)} MINUTES") |> str_wrap(70),
    subtitle = 
      "displaying the median session **minutes** and IQR",
    caption = glue("Note: Applicants falling into 'just clicked' count represent those who didn't have an event beyond viewing the agreement 
    {default_caption}") 
      ) +
  si_style() +
  theme(
    plot.subtitle = element_markdown(),
    strip.placement = "outside",
    strip.text = element_text(hjust = .5),
    panel.spacing=unit(0.5, "lines")
    )

```

### How long does the income data syncing take?

Syncing the data once the employer is chosen can take a bit of time to occur. The longer it takes, we may be more likely to see applicants drop off.

```{r}
#| label: data_sync

df_sync_init <- df_mp |> 
  filter(
    event %in% c("ApplicantAttemptedLogin","ApplicantSucceededWithLogin", "ApplicantFinishedSync"),
    ) |>
  distinct(distinct_id, cbv_flow_id, timestamp, event, pilot, provider) |> 
  arrange(distinct_id, cbv_flow_id, timestamp) |> 
  group_by(distinct_id, cbv_flow_id, event) |>
  mutate(attempt_n = row_number()) |> 
  ungroup() |>
  pivot_wider(
    names_from = event,
    values_from = timestamp
    ) |> 
  mutate(sync_time = ApplicantFinishedSync - ApplicantSucceededWithLogin)

df_sync <- df_sync_init |> 
  tidylog::filter(
    !is.na(sync_time), 
    sync_time >= 0
    ) 

df_sync_viz <- df_sync |> 
  group_by(pilot, provider) |> 
  summarise(
    n = n(),
    min = min(sync_time, na.rm = TRUE), 
    q25 = quantile(sync_time, 0.25, na.rm = TRUE),
    median = median(sync_time, na.rm = TRUE),
    q75 = quantile(sync_time, 0.75, na.rm = TRUE),
    max = max(sync_time, na.rm = TRUE),
    .groups = "drop"
    ) 

```

```{r}
#| label: long_sync

lng_run <- 180

v_lng_run_shr <- df_sync |> 
  count(sync_time > lng_run) |> 
  mutate(share = n / sum(n)) |> 
  filter(`sync_time > lng_run` == TRUE) |> 
  mutate(label = label_percent(1)(share)) |> 
  pull()

```

Overall, we are looking at a median sync time of `{r} median(df_sync$sync_time, na.rm = TRUE)` seconds, with 75% of events seeing it take under `{r} quantile(df_sync$sync_time, .75, na.rm = TRUE)` seconds. Of the `{r} scales::label_comma()(nrow(df_sync))` successful data syncs, `{r} v_lng_run_shr` take longer than `{r} lng_run` seconds to sync.

We can see how this places our when comparing different payroll aggregators used, Argyle and Pinwheel. Each pilot we can see there is a significant gap between the time range it takes to sync with Pinwheel versus Argyle.

```{r}
#| label: data_sync_tbl
#| eval: false

df_sync_viz |> 
  gt(groupname_col = "pilot") |> 
  fmt_number(columns = everything(), decimals = 0) |> 
  fmt_duration(columns = -n,
    input_units = "seconds"
    ) |> 
  adjust_row_padding() |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  add_labs(
    caption = default_caption
  )

```

```{r}
#| label: data_sync_viz
#| output: true
df_sync_viz |> 
  mutate(
    fill_color = ifelse(provider == "Argyle", dsac_color['light_navy'], dsac_color['light_teal']),
    provider = glue('{provider} (n = {label_comma()(n)})')) |> 
  ggplot(aes(y = fct_rev(provider), group = provider, color = fill_color)) +
  geom_linerange(aes(xmin = q25, xmax = q75)) +
  geom_point(aes(median), size = 4) +
  geom_text(
    aes(median, label = label_timespan(accuracy = 1)(median)), 
    family = "Source Sans 3", vjust = -1) +
  facet_grid(pilot ~. , switch = "y", scales = "free_y") +
  scale_x_continuous(label = label_timespan(), position = "top") +
  scale_color_identity() +
  labs(
    x = NULL, y = NULL,
    title = "Slightly shorter Pinwheel median sync, but a smaller sample size" |> toupper(),
    subtitle = 
      "displaying the median session **seconds** against the IQR",
    caption = default_caption 
      ) +
  si_style_xgrid() +
  theme(
    strip.placement = "outside",
    strip.text = element_text(hjust = .5),
    plot.subtitle = element_markdown(),
    panel.spacing=unit(0.5, "lines")
    )
```

Sticking with the provider comparison, we can look at the distribution of sync times. By bucketing them, we can see that most events have a sync time between 30 seconds and a minute (first 2 rows, green and dark blue bars) and about 95% are under the 3 minute mark (first 3 rows - green, dark blue, and blue columns).

```{r}
#| label: data_sync_bucketed_viz
#| output: true
df_sync_bucketed <- df_sync |> 
  mutate(
    sync_bucket = 
      case_when(
        sync_time <= 30 ~ "<=30s",
        sync_time <= 60 ~ ">30s - 1m",
        sync_time <= 180 ~ ">1m - 3m",
        sync_time <= 300 ~ ">3m - 5m",
        sync_time <= 600 ~ ">5m - 10m",
        TRUE ~ ">10m"
        ),
      sync_bucket = factor(sync_bucket, c("<=30s", ">30s - 1m", ">1m - 3m", ">3m - 5m", ">5m - 10m", ">10m"))
  ) |> 
  count(pilot, sync_bucket) |> 
  arrange(pilot, sync_bucket) |> 
  group_by(pilot) |> 
  mutate(
    share = n / sum(n),
    cum_share = cumsum(n) / sum(n)
    ) |> 
  ungroup()

  df_sync_bucketed |> 
    ggplot(aes(n, fct_rev(sync_bucket), fill = sync_bucket)) +
    geom_col() + 
    geom_text(
      aes(label = label_percent(1)(share)),
      family = "Source Sans 3", hjust = -.1, color = matterhorn, 
      ) + 
    facet_wrap(~pilot) +
    coord_cartesian(clip = "off") + 
    scale_fill_manual(values = unname(c(dsac_color['teal'], dsac_color['dark_navy'], dsac_color['navy'], dsac_color['light_navy'], dsac_color['light_cranberry'], dsac_color['cranberry']))) +
    labs(
      x = NULL, y = NULL,
      title = "95% OF SYNC TIMES ARE UNDER THREE MINUTES",
      subtitle = "number of sessions' income sync time",
      caption = default_caption) +
    si_style_xgrid() +
    theme(legend.position = "none")    
```

The next visual looks at the same data, but plots each of the event individually, allowing us to see some of the larger outliers and where the specific times fall compared within the broader buckets. The x-axis has been truncated to 20 minutes to see the distribution, plotting the `r dplyr::filter(df_sync, sync_time > 1200) |> nrow()` outliers on the 20 minute mark. Both providers saw three events with sync times over 20 minutes in the November pilot, but the median time went down from August.

```{r}
#| label: data_sync_distro_viz
#| output: true 
 
 df_sync |>
    mutate(
      sync_bucket = 
        case_when(
          sync_time <= 30 ~ "<=30s",
          sync_time <= 60 ~ ">30s - 1m",
          sync_time <= 180 ~ ">1m - 3m",
          sync_time <= 300 ~ ">3m - 5m",
          sync_time <= 600 ~ ">5m - 10m",
          TRUE ~ ">10m"
          ),
      sync_bucket = factor(sync_bucket, c("<=30s", ">30s - 1m", ">1m - 3m", ">3m - 5m", ">5m - 10m", ">10m"))) |> 
    ggplot(aes(sync_time, fct_rev(pilot), color = sync_bucket)) +
    geom_point(position = position_jitter(height = 0.3, seed = 42), alpha = 0.4) + 
    stat_summary(fun = "median", color = dsac_color['gold'], shape = 23, linewidth = 1.1, na.rm = TRUE) + 
    facet_grid(provider ~. , switch = "y", scales = "free_y") + 
    scale_x_continuous(
      label = label_number(.1, scale = 1/60, suffix = "m"), limits = c(0, 1200),
      breaks = seq(0, 1200, 150),
      oob=scales::squish, position = "top") +
    scale_color_manual(values = unname(c(dsac_color['teal'], dsac_color['dark_navy'], dsac_color['navy'], dsac_color['light_navy'], dsac_color['light_cranberry'], dsac_color['cranberry']))) +
    labs(
      x = NULL, y = NULL, 
      title = "MEDIAN SYNC TIME IMPROVED IN NOVEMBER PILOT",
      subtitle = "income sync time with provider | each point represents a session | gold diamonds represent the median" |> str_wrap(),
      caption = glue("Note: Sync time capped at 20 minutes
      {default_caption}")) +
    si_style_xgrid() +
    theme(
      strip.text = element_text(hjust = .5),
      strip.placement = "outside",
      legend.position = "none"
      )
```

### When there was a provider outage, was there any change in processing times?

During the November pilot, Argyle had an outage between November 19-20. Looking by day, we can see that Monday, November 20th had a dip in the number of Argyle events compared with the prior day and Pinhweel saw an increase on both November 19th and 20th (though certainly not enough to offset the dip). During the first day of the outage, the success rate of logging for both providers dropped precipitously, but rebounded on November 20th.

```{r}
#| label: sync_outage
#| output: true
#| fig-height: 7

df_outage_viz_rt <- df_sync_init |> 
  filter(
    pilot == "Nov 2025",
    !is.na(ApplicantAttemptedLogin),
    ) |> 
  mutate(
    date = as_date(ApplicantAttemptedLogin),
    succeeded = !is.na(ApplicantFinishedSync)
  ) |> 
  group_by(date, provider, distinct_id, cbv_flow_id) |> 
  summarize(succeeded = max(succeeded, na.rm = TRUE), .groups = "drop") |> 
  group_by(date, provider) |> 
  summarize(
    attempted = n_distinct(distinct_id, cbv_flow_id),
    succeeded = sum(succeeded, na.rm = TRUE),
    .groups = "drop"
  ) |> 
  mutate(
    success_rate = succeeded/attempted,
    fillcolor = ifelse(provider == "Argyle", dsac_color['light_navy'], dsac_color['light_teal']),
    provider_x = ifelse(provider == "Argyle", -.08, -.05),
    date_fmt = case_when(
      date %in% c('2025-11-17', '2025-12-01') ~ format(date, format = "%b %d"),
      month(date) == 11 ~ format(date, format = "%d"),
      month(date) == 12 ~ format(date, format = " %d"),
      ) |> fct_inorder()
    )

df_outage_viz_rt |> 
  ggplot(aes(y = fct_rev(date_fmt), color = fillcolor, , fill = fillcolor, group = date_fmt)) +
  geom_line(aes(success_rate), color = "#909090") + 
  geom_point(aes(success_rate), size = 3, shape = 21, color = "white") +
  geom_point(aes(provider_x, size = attempted), shape = 15) +
  geom_text(
    aes(provider_x - .02, label = attempted),
    data = df_outage_viz_rt |> filter(provider == "Argyle"), 
    family = "Source Sans 3", hjust = 1, color = "#505050") + 
  geom_text(
    aes(provider_x + .04, label = attempted),
    data = df_outage_viz_rt |> filter(provider != "Argyle"), 
    family = "Source Sans 3", hjust = 1, color = "#505050") + 
  annotate(
    geom = 'rect',
    ymin = 29.5, ymax = 31.5,
    # ymin = '2025-11-19', ymax = '2025-11-19',
    xmin = -Inf, xmax = Inf,
    alpha = .3, fill = "#909090"
    ) +
  scale_x_continuous(
    labels = label_percent(), 
    breaks = seq(0, 1, .2), 
    minor_breaks = seq(0, 1, .1),
    position = "top") + 
  scale_color_identity(aesthetics = c('fill', 'color')) +
  scale_size(guide = "none") +
  labs(
    x = NULL, y = NULL,
    title = "ARGYLE USERS TYPICALLY SAW A HIGHER SUCCESSFUL LOGIN RATE",
    subtitle = glue("daily <span style = color:{dsac_color['light_navy']};>**Argyle**</span>/<span style = color:{dsac_color['light_teal']};>**Pinwheel**</span> applicant flow attempts to login [left] and  successful rates [right]"),
    caption = glue('Note: Argyle outage Nov 19-20
    {default_caption}')
  ) + 
  si_style_xgrid() +
  theme(plot.subtitle = element_markdown())

#si_save(here("app/analytics/success_rate.png"), height = 7)
```

During those two Argyle outage days, Pinwheel had the two highest median data sync times for the fives weeks of the pilot.

```{r}
#| label: sync_outage2
#| output: true
#| fig-height: 7

df_outage_viz <- df_sync |> 
  filter(
    pilot == "Nov 2025",
    !is.na(ApplicantAttemptedLogin)
    ) |> 
  mutate(date = ApplicantAttemptedLogin |> as_date()) |> 
  group_by(date, provider) |> 
  summarize(
    n = n_distinct(distinct_id, cbv_flow_id),
    q25 = quantile(sync_time, 0.25, na.rm = TRUE),
    median = median(sync_time, na.rm = TRUE),
    q75 = quantile(sync_time, 0.75, na.rm = TRUE),
    .groups = "drop"
    ) |> 
  mutate(
    fillcolor = ifelse(provider == "Argyle", dsac_color['light_navy'], dsac_color['light_teal']),
    provider_x = ifelse(provider == "Argyle", -35, -20),
    date_fmt = case_when(
      date %in% c('2025-11-17', '2025-12-01') ~ format(date, format = "%b %d"),
      month(date) == 11 ~ format(date, format = "%d"),
      month(date) == 12 ~ format(date, format = " %d"),
      ) |> fct_inorder()
  )

df_outage_provider_median <- df_sync |> 
  filter(
    pilot == "Nov 2025",
    !is.na(ApplicantAttemptedLogin)
    ) |> 
  mutate(date = ApplicantAttemptedLogin |> as_date()) |> 
  group_by(provider) |> 
  summarize(median_provider = median(sync_time, na.rm = TRUE) |> as.numeric()) |> 
  ungroup() |> 
  pivot_wider(names_from = provider, values_from = median_provider)

df_outage_viz |> 
  ggplot(aes(y = fct_rev(date_fmt), color = fillcolor, group = provider)) +
  geom_linerange(aes(xmin = q25, xmax = q75), position = position_dodge(.9,  orientation = "y")) +
  geom_point(aes(provider_x, size = n), shape = 15) + 
  geom_text(
    aes(provider_x -10, label = n),
    data = df_outage_viz |> filter(provider == "Argyle"), 
    family = "Source Sans 3", hjust = 1, color = "#505050") + 
  geom_text(
    aes(provider_x + 14, label = n),
    data = df_outage_viz |> filter(provider != "Argyle"), 
    family = "Source Sans 3", hjust = 1, color = "#505050") + 
  geom_point(aes(median), position = position_dodge(.9, orientation = "y")) +
  annotate(
    geom = 'rect',
    ymin = 29.5, ymax = 31.5,
    xmin = -Inf, xmax = Inf,
    alpha = .3, fill = "#909090"
    ) + 
  scale_x_continuous(
    limit = c(-45,300), 
    label = label_number(1, scale = 1/60, suffix = "m"),
    breaks = seq(0, 300, 60),
    oob = scales::squish, 
    position = "top") + 
  scale_color_identity() +
  scale_size(guide = "none") +
  labs(
    x = NULL, y = NULL,
    title = glue("DESPITE SOME LARGE OUTLIERS AND LESS FLOWS, PINWHEEL'S MEDIAN SYNC TIME ({df_outage_provider_median$Pinwheel}s) IS ONLY A FEW SECONDS SLOWER THAN ARGYLE ({df_outage_provider_median$Argyle}s)") |> str_wrap(70),
    subtitle = glue("successful daily <span style = color:{dsac_color['light_navy']};>**Argyle**</span>/<span style = color:{dsac_color['light_teal']};>**Pinwheel**</span> applicant flow syncs [left] and their duration, **minutes** [median + IQR]"),
    caption = glue('Note: x axis truncated to 5 minutes; Argyle outage Nov 19-20 
    {default_caption}')
  ) + 
  si_style_xgrid() +
  theme(plot.subtitle = element_markdown())

#si_save(here("app/analytics/sync_times.png"), height = 7)
```

## Where in the process are applicants dropping off?

To get a sense of where applicants are dropping off, we can look at some key points/pages to see whether they reached that step. The Sankey diagram below depicts these key points in the November 2025 pilot.

```{r}
#| label: event_steps

v_steps <- c(
  "ApplicantViewedAgreement",
  "ApplicantAgreed",
  "ApplicantSelectedEmployerOrPlatformItem",
  "ApplicantAttemptedLogin",
  "ApplicantSucceededWithLogin",
  "ApplicantViewedPaymentDetails",
  "ApplicantSharedIncomeSummary"
  )

v_steps_clean <- 
  tibble(event = v_steps) |> 
  add_row(event = "dropped", .before = 1) |> 
  clean_events() |> 
  pull()

v_steps_breaks <- str_replace_all(v_steps_clean, " ", "\n")
```

```{r}
#| label: event_journey

#setup full set of steps for each applicant to id drop off point
df_journey <- df_mp |> 
  filter(
    pilot == "Nov 2025", 
    event %in% v_steps) |> 
  mutate(
    event = factor(event, v_steps),
    status = "reached"
  ) |> 
  select(pilot, distinct_id, event, status) |> 
  distinct(pilot, distinct_id, event, status) |> 
  complete(pilot, distinct_id, event) |> 
  arrange(distinct_id, event) |> 
  clean_events()

#apply step order # and label drop point
df_journey <- df_journey |> 
  group_by(pilot, distinct_id) |> 
  mutate(
    step_order = row_number(),
    step_event =  case_when(
      status == "reached" ~ as.character(event_clean), 
      is.na(status) & lag(status) == "reached" ~ "dropped"
    )) |>
  ungroup() %>%
  filter(!is.na(step_event)) |> 
  select(-c(event, event_clean, status)) |> 
  mutate(step_event = factor(step_event, v_steps_clean))

#value labels to merge on with long dataset
df_journey_label <- df_journey |> 
  count(step_order, step_event) |> 
  mutate(step_order = glue("step_{step_order}") |> as.character()) |> 
  group_by(step_order) |> 
  mutate(share = n / sum(n)) |> 
  ungroup()

#spread to setup for sankey plot
df_journey <- df_journey |> 
  pivot_wider(
    names_from = step_order,
    values_from = step_event,
    names_prefix = "step_"
  )


# Convert to long format for ggsankey
df_sankey <- df_journey %>%
  make_long(step_1, step_2, step_3, step_4, step_5, step_6, step_7) |> 
  filter(!is.na(node)) |> 
  mutate(
    node = factor(node, v_steps_clean),
    next_node = factor(next_node, v_steps_clean),
    fill_color = ifelse(node == "dropped", dsac_color[['light_cranberry']], dsac_color[['light_navy']])
   )

#apply value for labeling
df_sankey <- df_sankey |> 
  left_join(
    df_journey_label,
    by = join_by(x == step_order, node == step_event)
  ) |> 
  mutate(value_label = ifelse(x == "step_1", label_comma()(n), glue("{label_comma()(n)}\n{label_percent(1)(share)}")))

```

```{r}
#| label: event_journey_sankey
#| output: true

#viz
df_sankey |> 
  ggplot(
    aes(x = x, 
        next_x = next_x, 
        node = node, 
        next_node = next_node,
        fill = fill_color,
        label = value_label
      )) +
  geom_sankey(flow.alpha = 0.2, flow.fill = matterhorn, node.color = "gray30", width = 0.1, na.rm = TRUE) +
  geom_sankey_label(
    size = 4, color = "white",  hjust = 1.4,
    family = "Source Sans 3", na.rm = TRUE,
  ) +
  scale_x_discrete(labels = v_steps_breaks[2:8], position = "top") +
  scale_fill_identity() + 
  coord_cartesian(clip = 'off') +
  labs(
    x = NULL, y = NULL,
    title = "Significant drop off in applicants agreeing to the terms" |> toupper(),
    subtitle = glue("Number/share of Nov 2025 applicants <span style = color:{dsac_color['light_cranberry']};>dropping off</span> at key points in the application process"),
    caption = default_caption
   ) +
  si_style_nolines() + 
  theme(
    axis.text.y = element_blank(),
    axis.text.x = element_markdown(),
    plot.subtitle = element_markdown()
  ) 
```

Right off the bat, we can see that off the `{r} scales::label_comma()(df_journey_label[df_journey_label$step_order == "step_1",]$n)` applicants who started the process, only `{r} scales::label_percent(1)(df_journey_label[df_journey_label$step_event == "Agreed",]$share)` agreed to terms to move on, and only `{r} scales::label_percent()(df_journey_label[df_journey_label$step_event == "Shared Income Summary",]$n/df_journey_label[df_journey_label$step_order == "step_1",]$n)` actually made it to completion, submitting their pay information. The diagram also show that about 1 in 3 applicants is dropping off when selecting their employer, logging in, and then succeeding with that log in.

The table below so similar drop off rates at each step for each of the three pilots in Lousiana.

```{r}
#| label: event_table
#| output: true

df_ret <- df_mp |>
  filter(event %in% v_steps) |> 
  mutate(event = factor(event, v_steps)) |> 
  arrange(pilot, event) |> 
  clean_events() |> 
  mutate(event_clean = fct_inorder(event_clean)) |> 
  select(pilot, distinct_id, event_clean) |> 
  distinct(pilot, distinct_id, event_clean) |> 
  count(pilot, event_clean, sort = TRUE, name = "events") |> 
  group_by(pilot) |> 
  mutate(
    share_lag = events / lag(events),
    share_cumlative = events / max(events),
    share_cumlative = ifelse(event_clean == "Viewed Agreement", NA, share_cumlative)
      ) |> 
  ungroup() |> 
  arrange(pilot, event_clean) |> 
  mutate(event_clean = as.character(event_clean))

df_ret |>
  gt(groupname_col = "pilot") |> 
  cols_label(
    event_clean = "", 
    share_lag = "Share of Prior Event",
    share_cumlative = "Share of Those Starting"
  ) |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  adjust_row_padding() |> 
  format_numeric_columns() |> 
  sub_missing()

```

### Are applicants accessing the documentation (help or FAQ) before dropping off?

The prior section gave use a sense of where applicants were dropping off. It may be useful to see if applicants are accessing the documentation before they abort the application. Looking at the data, we can see that on average, those who completed the application had slight more "help actions" than those who did not. This of course is affected by the fact that those who continued saw more pages than those who did not or that using the help more they were more likely to find what they needed to continue onward.

```{r}
#| label: help_events
v_help_events <- c(
  "ApplicantOpenedHelpModal",
  "ApplicantViewedHelpText", 
  "ApplicantViewedHelpTopic", 
  "ApplicantManuallySwitchedLanguage")
```

```{r}
#| label: help_actions_summary

df_help_actions <- df_time |> 
  mutate(
    completed = as.logical(completed),
    help = event %in% v_help_events,
    started = event == "ApplicantViewedAgreement", #needed for Aug pilot
    distinct_id_started = case_when(started == TRUE ~ distinct_id),
    cbv_flow_id_started = case_when(started == TRUE ~ cbv_flow_id),
    distinct_id_help = case_when(event %in% v_help_events ~ distinct_id),
    ) |> 
  group_by(pilot, completed) |> 
  summarize(
    applicants = n_distinct(distinct_id_started, na.rm = TRUE),
    applicants_with_help_actions = n_distinct(distinct_id_help, na.rm = TRUE),
    sessions = n_distinct(distinct_id_started, cbv_flow_id_started, na.rm = TRUE), 
    help_actions = sum(help, na.rm = TRUE),
    .groups = "drop"
  ) |> 
  mutate(
    help_rate_per_app = help_actions / applicants,
    help_rate_per_sess = help_actions / sessions,
    click_rate_probability = applicants_with_help_actions / applicants
    )

```

```{r}
#| label: help_actions_viz
#| output: true

df_help_actions |> 
  select(pilot, completed, help_rate_per_app, help_rate_per_sess, click_rate_probability) |> 
  pivot_longer(-c(pilot, completed), names_to = "metric") |> 
  mutate(
    metric = 
      case_match(
        metric,
        "click_rate_probability" ~ "**Help Button Click Probability (%)**<br>(help actions / applicants)",
        "help_rate_per_app" ~ "**Help Button Clicks per 100 Applicants**<br>(help actions / applicants)",
        "help_rate_per_sess" ~ "**Help Button Clicks per 100 Sessions**<br>(help actions / sessions)"
        ),
    mark_color = ifelse(completed == TRUE, dsac_color['light_navy'], dsac_color['light_cranberry']),
    mark_fill = ifelse(completed == TRUE, dsac_color['light_navy'], "white") 
  ) |> 
  ggplot(aes(value, fct_rev(pilot), color = mark_color, fill = mark_fill, group = pilot)) +
  geom_path(color = matterhorn) +
  geom_point(size = 4, shape = 21, stroke = 1.1) +
  geom_text(aes(label = label_number(1, scale = 1*100)(value)), family = "Source Sans 3", color = matterhorn, vjust = -1) +
  facet_wrap(. ~ metric, ncol = 1, strip.position = "top") +
  scale_fill_identity() +
  scale_color_identity() +
  scale_x_continuous(labels = label_number(scale = 1*100)) + 
  si_style_xgrid() +
  labs(
    x = NULL, y = NULL,
    title = "HELP USAGE INCREASED EACH PILOT",
    subtitle = glue("Comparing usage across applicants/sessions that were <span style = color:{dsac_color['light_cranberry']};>**incomplete**</span> vs <span style = color:{dsac_color['light_navy']};>**completed**</span>"),
    caption = glue("Note: A help action is when an applicant accesses the help, FAQ, or language change
    {default_caption}")
    ) +
  theme(
    panel.spacing = unit(.5, "lines"),
    axis.text.x = element_blank(),
    strip.text.y = element_text(hjust = .5),
    strip.placement = "outside",
    plot.title = element_markdown(),
    plot.subtitle = element_markdown(),
    strip.text = element_markdown(),
    legend.position = "none"
  )

```

We can investigate this further, looking at the total help actions by page, comparing whether the applicant continued on past that page or ended there. We can see that most of the agreement page are on the agreement. There is significantly more usage of the help[^2] than those who used help on that page but continued on to the next page.

[^2]: In this particular case, we are looking at the number of times the help or FAQ was access, so we can have multiple help access points by applicant on the same page

```{r}
#| label: help_viz
#| output: true

v_page_order <- tibble(event = c("LandingPage", v_steps)) |> clean_events() |> pull()

df_help <- df_time |> 
  left_join(
    tibble(
      event_order = 1:length(v_steps), 
      event = v_steps
      ) |> 
    clean_events() |> 
    rename(page = event_clean),
    by = "event"
  ) |>
  group_by(pilot, distinct_id, cbv_flow_id) |> 
  fill(page, .direction = "up") |> 
  fill(event_order, .direction = "up") |> 
  mutate(
    event_order = ifelse(is.na(event_order), 0, event_order),
    page = ifelse(is.na(page), "Landing Page", page)
    ) |> 
  mutate(
    page = factor(page, v_page_order),
    last_page = event_order == max(event_order, na.rm = TRUE),
    accessed_help = event %in% v_help_events
      ) |> 
  ungroup() |> 
  group_by(pilot, distinct_id, cbv_flow_id, page, last_page) |> 
  mutate(accessed_help = max(accessed_help, na.rm = TRUE)) |> 
  ungroup()


df_help_viz <- df_help  |> 
  mutate(
    started = event == "ApplicantViewedAgreement", #needed for Aug pilot
    distinct_id_started = case_when(started == TRUE ~ distinct_id),
    cbv_flow_id_started = case_when(started == TRUE ~ cbv_flow_id),
    distinct_id_help = case_when(event %in% v_help_events ~ distinct_id),
  ) |> 
  group_by(pilot, page, last_page) |> 
  summarise(
    n_applicants = n_distinct(distinct_id_started),
    sessions = n_distinct(distinct_id_started, cbv_flow_id_started),
    accessed_help = sum(accessed_help, na.rm = TRUE),
    .groups = "drop"
  ) |> 
  mutate(
    fill_color = ifelse(last_page == TRUE, dsac_color['light_cranberry'], dsac_color['light_navy']),
    last_page_lab = ifelse(last_page == TRUE, "Last Page", "Continued On")
    )

df_help_viz |> 
  ggplot(aes(accessed_help, fct_rev(page), color = fill_color)) +
  geom_linerange(
    aes(xmin = 0, xmax = accessed_help),
    position = position_dodge(.5,  orientation = "y")
    ) + 
  geom_point(position = position_dodge(.5,  orientation = "y")) +
  facet_wrap(pilot~.) +
  labs(
    x = NULL, y = NULL, 
    title = "Help actions higher for applicants continuing" |> toupper(),
    subtitle = glue("Help button clicks comparing applicants who <span style = color:{dsac_color['light_cranberry']};>**ended on that page**</span> or <span style = color:{dsac_color['light_navy']};>**continued on**</span>"),
    caption = default_caption
    ) +
  scale_color_identity() + 
  scale_fill_identity() + 
  scale_x_continuous(label = label_number(scale_cut = cut_short_scale())) +
  si_style_xgrid() +
  theme(plot.subtitle = element_markdown())

```

### How many applicants are not finding their employer in the search?

```{r}
#| label: search_results

df_search <- df_mp |> 
  mutate(
    picked = event == "ApplicantClickedPopularAppEmployers",
    searches = event == "ApplicantSearchedForEmployer",
    missingresults = event == "ApplicantAccessedMissingResultsPage",
    started = event == "ApplicantViewedAgreement", #needed for Aug pilot
    distinct_id_started = case_when(started == TRUE ~ distinct_id),
    cbv_flow_id_started = case_when(started == TRUE ~ cbv_flow_id),
    ) |> 
  group_by(pilot) |> 
  summarise(
    applicants = n_distinct(distinct_id_started),
    sessions = n_distinct(cbv_flow_id_started),
    picked = sum(picked, na.rm = TRUE),
    searches = sum(searches, na.rm = TRUE),
    missingresults = sum(missingresults, na.rm = TRUE),
    .groups = "drop"
    ) |> 
  mutate(
    share_missing = missingresults/searches,
    applicants = ifelse(pilot == "May 2025", NA_integer_, applicants)
    )
```

One reason for retention to drop off could be from applicant not able to find their employers or platforms in in the search. Across all pilots, the average share of missing results is quite high at `r label_percent(1)(sum(df_search$missingresults) / sum(df_search$searches))`. This could be a major roadblock for applicants. In the November pilot, `r label_percent(1)(df_journey_label[df_journey_label$step_order == "step_3" & df_journey_label$step_event == "dropped",]$share)` of applicants fell off at this step.

```{r}
#| label: search_results_tbl
#| output: true
 
df_search |> 
  gt() |> 
  adjust_row_padding() |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  format_numeric_columns() |> 
  cols_label(
    picked = md("Employer<br>Picked Popular"),
    searches = md("Employer<br>Searches"),
    missingresults = md("Employer Searches<br> Returned Missing"),
    share_missing = md("Share<br>Missing")
  ) |> 
  sub_missing() |> 
  add_labs(
    title = "ABOUT ONE IN FIVE SEARCH RESULTS ARE MISSING EACH PILOT PERIOD",
    caption = default_caption
  ) 
```

### Are the popular app employers the right ones (i.e. do there appear to be employers searched more frequently than any that appear in the popular links)

From the table in the last section, we can see that the number of searches and popular employer picks remains relatively the same each pilot. Overall, for every 1 popular employer picked, there are `r label_number(.1)(sum(df_search$searches) / sum(df_search$picked))` searches. If we look at the top 10 employers. Wal-Mart has been the top employer selected each pilot period and has been significantly larger than the next few employers combined. It is important to note that many employers are not being captured in this process and when aggregated, rank as the second most "chosen" employer. Amazon, Waffle House, and doordash have consistently been ranked in the top 10 each pilot. Given the small numbers at this stage, it likely don't make sense to change the popular employer selector buttons.

```{r}
#| label: pop_employers

df_top <- df_mp |> 
  filter(event == "ApplicantFinishedSync") |>
  mutate(employer_name = ifelse(is.na(employer_name), "[not captured]", employer_name)) |> 
  count(pilot, employer_name, sort = TRUE) |> 
  group_by(pilot) |> 
  mutate(
    share = n / sum(n),
    rank = rank(-n, ties.method = "random")
    ) |> 
  slice_head(n = 50) |> 
  ungroup() 

df_top <- df_top |> 
  left_join(
    df_top |> 
  filter(rank <= 10) |> 
  select(pilot, employer_name) |> 
  group_by(employer_name) |> 
  mutate(empl_lab = case_when(row_number() == 1 ~ employer_name)) |> 
  ungroup()
  ) 
  

# df_top <- df_top |> 
#   mutate(fill_color = case_when(
#     pilot == latest_pilot & rank == 1 ~ dsac_color['light_navy'],
#     pilot == latest_pilot & rank == 2 ~ dsac_color['light_cranberry'],
#     pilot == latest_pilot & rank == 3 ~ dsac_color['light_teal']
#     )) |>
#   group_by(employer_name) |> 
#   fill(fill_color, .direction = "updown") |> 
#   ungroup() |> 
#   mutate(fill_color = ifelse(is.na(fill_color), matterhorn, fill_color))
  


df_top |>
  ggplot(aes(pilot, rank, color = employer_name)) +
  geom_point(size = 4.5)  +
  geom_text(
    aes(label = empl_lab), vjust = -1,
    na.rm = TRUE, family = "Source Sans Pro", color = matterhorn, size = 9/.pt, 
    ) +
  geom_text(
    aes(label = n), vjust = 2,
    na.rm = TRUE, family = "Source Sans Pro", color = matterhorn, size = 9/.pt, 
    ) +
  geom_bump(linewidth = 2, smooth = 8) +
  scale_y_reverse(expand = c(.05, .05)) +
  scale_color_manual(
    values = c(
      "Wal-Mart Associates, Inc." = unname(dsac_color['light_navy']),
      "[not captured]" = unname(dsac_color['light_cranberry']),
      "Amazon.com Services LLC" = unname(dsac_color['light_teal']),
      rep("gray50", length(unique(df_top$employer_name)) - 3)
      )) +
  # scale_color_manual(values = rep("gray50", length(unique(df_top$employer_name)))) +
  coord_cartesian(ylim=c(0, 10)) +
  si_style_nolines() +
  labs(
    x = NULL, y = NULL,
    title = "TOP EMPLOYERS SELECTED BOUNCE AROUND",
    subtitle = "top 10 employers submitted each pay period (number of searches below)",
    caption = default_caption
    ) +
  theme(
    legend.position = "none",
    axis.text.y = element_blank())

si_save(here("app/analytics/employer_bumpchart.png"))
```

![](employer_bumpchart.png)

```{r}
#| label: missing_empl

df_missing_empl <- df_mp |> 
  filter(event == "ApplicantFinishedSync") |> 
  count(pilot, provider, is.na(employer_name)) |> 
  pivot_wider(
    names_from = `is.na(employer_name)`,
    values_from = n
  ) |> 
   arrange(desc(provider), pilot) |> 
   mutate(
    total_events = `FALSE` + `TRUE`,
    missing = `TRUE`,
    share_missing = missing/(`FALSE` + `TRUE`)
  ) |> 
   select(-`FALSE`, -`TRUE`)

```

As mentioned above, we can see that many employers are not being captured in this process. If we break down where this is occuring, we can see it is almost exclusively coming from Pinwheel. In the most November pilot, `r label_percent()(df_missing_empl[df_missing_empl$provider == "Pinwheel" & df_missing_empl$pilot == "Nov 2025",]$share_missing)` of the synced data were missing an employer name.

```{r}
#| label: missing_empl_tbl
#| output: true

 df_missing_empl|> 
   gt(groupname_col = "provider") |> 
    format_numeric_columns() |> 
    tab_spanner(
    label = "# of events",
    columns = c(total_events, missing)
  ) |> 
    cols_label(
  pilot= "",
    total_events = "Total", 
    missing = "Missing",
    share_missing = md("Share<br>Missing<br>Employer")
  ) |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  adjust_row_padding() |> 
    tab_style(
    style = list(
      cell_text(color = dsac_color['light_cranberry'], weight = "bold")
      ),
    locations = cells_body(
      columns = share_missing,
      rows = share_missing > .1
    )
  )
```

## How many sessions does it take a applicant to complete the process?

```{r}
#| label: returning

max_scale <- 12

df_sessions <- df_device_origin_status |>
  filter(!pilot %in% c("May 2025")) |> 
  count(pilot, distinct_id, initiation, sort = TRUE) |> 
  mutate(fill_color = ifelse(n <= max_scale, "#909090", dsac_color['light_cranberry']))


# df_sessions |> 
#   group_by(pilot) |> 
#   count(n > max_scale) |> 
#   mutate(share = n / sum(n))


df_sessions_multi <- df_sessions |>
  mutate(type = ifelse(n == 1, "single", "multi")) |> 
  count(pilot, type) |> 
  group_by(pilot) |> 
  mutate(share = n / sum(n)) |> 
  ungroup() |> 
  filter(type == "multi") 

df_sessions |> 
  count(pilot, n > 1) |> 
  mutate(share = n / sum(n)) 

v_many_sessions <- df_sessions |> 
  count(n > max_scale) |> 
  mutate(share = n / sum(n)) |> 
  filter(`n > max_scale` == TRUE) |> 
  pull()
```

After the May 2025 pilot, the team implemented changes to allow for better tracking of applicants, allowing us to see if the same users were returning to the application. Ideally, if this application were incredibly easy to complete, we would see most using completing in one session. In the histogram below, we can see that the November 2025 had far more repeated users. The number of users who had two or more sessions increased from `r scales::label_percent()(df_sessions_multi[df_sessions_multi$pilot == "Oct 2025",]$share)` in October up to `r scales::label_percent()(df_sessions_multi[df_sessions_multi$pilot == "Nov 2025",]$share)` in November, which is a pretty sizable increase.

```{r}
#| label: returning_viz
#| output: true

df_sessions |>
  filter(n <= max_scale) |> 
  ggplot(aes(n, fill = initiation)) +
  geom_histogram(fill = dsac_color['light_navy'],color = "white", bins = max_scale) +
  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
  scale_x_continuous(
    limits = c(0, max_scale +1),
    breaks = seq(1, max_scale, 1),
    oob=scales::squish
  ) +
  facet_wrap(pilot~.) + 
  labs(
    x = NULL, y = NULL,
    title = "INCREASE IN NUMBER OF SESSIONS PER APPLICANT IN NOVEMBER",
    subtitle = "the number of applicants by session",
    caption = glue("Note: The number of sessions is capped at {max_scale}, less than {label_percent(.1)(v_many_sessions)} across pilots had more sessions 
      {default_caption}")
  ) +
  si_style_ygrid() +
  theme(panel.spacing = unit(.5, "lines"))
```

Not show in the histogram are applicants who are starting the process more than `r max_scale` times. These applicants represent a small number of the total applicants, but the behavior does not seem realistic. This issue would merit some investigation as to whether these are really the same applicants, with cases sessions ranging from `r max_scale + 1` to `r max(df_sessions$n)` sessions.

```{r}
#| label: returning_viz_points
#| output: true
df_sessions |> 
  ggplot(aes(n, fct_rev(pilot), color = fill_color)) +
  geom_point(position = position_jitter(height = 0.3, seed = 42), alpha = 0.4) +
  scale_x_continuous(
    limits = c(0, 50),
    oob=scales::squish
  ) +
    scale_color_identity() + 
    labs(
      x = NULL, y = NULL,
      title = glue("ABOUT {label_percent(.1)(v_many_sessions)} OF APPLICANTS HAD <span style = color:{dsac_color['light_cranberry']};>MORE THAN {max_scale} SESSIONS</span>"),
      subtitle = "Each point represents an applicant's number of sessions",
       caption = glue("Note: The number of sessions is capped at 50 
      {default_caption}")
      ) +
    si_style_xgrid() +
    theme(plot.title = element_markdown())
```

```{r}
#| label: user_multi_sessions_deep_dive

  df_mp |> 
    filter(distinct_id == "applicant-533661") |> 
    mutate(completed = event == "ApplicantSharedIncomeSummary") |> 
    group_by(#day = date(timestamp), 
    cbv_flow_id) |> 
    summarise(
      start = min(timestamp),
      end = max(timestamp),
      completed = max(completed, na.rm = TRUE),
      .groups = "drop"
    ) |> 
      mutate(
        cbv_flow_id = as.character(cbv_flow_id),
        day = date(start),
        pm = ifelse(pm(start), "pm", "am"),
        across(c(start, end), hms::as_hms),
        completed = as.logical(completed)
        ) |> 
      ggplot(aes(y = fct_rev(cbv_flow_id), group = cbv_flow_id)) +
      geom_linerange(aes(xmin = start, xmax = end, color = completed)) +
      # geom_point(aes(start), shape = 21, fill = "blue", alpha = .5) + 
      # geom_point(aes(end), shape = 21, fill = "red", alpha = .5) + 
      geom_point(aes(start), shape = 21, size = 4, fill = "white") + 
      geom_point(aes(end), shape = 4, size = 4, fill = "red", alpha = .5) + 
      facet_grid(pm~fct_rev(as.character(day)), scales = "free", space = "free_y") + 
      si_style_xgrid()
```

In the November pilot, there were `r  scales::label_comma()(df_compl_pilot[df_compl_pilot$pilot == "Nov 2025" & df_compl_pilot$denom == "applicants", ]$"Shared Income Summary")` applicants who completed the process, submitting their income summary. Was this an easy process? For the applicants who used the tokenized link, we can track how many sessions it took them to complete the process, ideally one and done. So keeping with the November pilot,

### How many applicants clicked on the link and then came back another time to complete the process?

When getting a link, its assumed many people open that link to determine what they need to do and come back later to complete if it doesn't seem easy and/or quick to complete. We can look to see how many sessions were solely opening the link and not continuing on.

### \[SUB SECTIONS IN PROGRESS\]

```         
-   How many applicants clicked on the link and then came back another time to complete the process?
-   How many applicants finished in one try? How long did it take compared with the overal rate?
```

-   How many times does an applicant "browser back"?