---
title: "FFS Analytic review"
execute:
  echo: false
  output: false
  warning: false
  cache: true
format:
  html:
    toc: true
    number-sections: true
    css: dsac-theme.css
  docx:
    toc: true
    number-sections: true
    reference-doc: custom-reference-doc.docx
    highlight-style: github
---

# Purpose

Over the past year, the Centers for Medicare and Medicaid Services (CMS) in conjunction with partner states have piloted an online income verification application. With each phase, analysts have explore the web analytics data, looking into applicant uptake and utilization of the tool. This specific report aims identify areas of the tool where retention drops in an effort to improve the product design, making it easier for applicants to complete the full form.

## Key Questions

Below are the areas the report seeks to explore to help improve the product design.

1.  How many users are starting but not completing the process?
2.  Where in the process are users dropping off?
3.  Does time appear to be a factor in dropping off?
    1.  How long does the data syncing with Argyle/Pinwheel take?
4.  Are users accessing the documentation (help or FAQ) before dropping off?
5.  How many users are not finding their employer in the search?
6.  Are the popular app employers the right ones (i.e. do there appear to be employeers searched more frequently than any that appear in the popular links)
7.  What share of users are return users? (tokenized users)
    1.  How many sessions does it take a user to complete the process?
    2.  How many users clicked on the link and then came back another time to complete the process?
8.  Do we see a difference in completion rates if users are accessing from mobile vs desktop?
9.  How many times does a user "browser back"?

-   Possible Comparisions
    -   device types
    -   pilot periods/weeks

## Method

This report was generated using a Quarto notebook and leverage R for all analysis and visualizations. The analysis focuses on the 2025 Lousiana pilot, which had three, 6-week session starting May, August, and November. The web analytics data come from Mixpanel, accessed using python for the API call with a [Jupyter Notebook](https://github.com/DSACMS/iv-cbv-payroll/blob/main/app/analytics/analytics.ipynb). All of the underlying code can be found on [GitHub](https://github.com/DSACMS/iv-cbv-payroll/tree/main/app/analytics).

## Defintions/Calculations

Its easy to construct similar metrics in different ways and yield slightly different results. For tranparency, below are some definitions to key concepts or calculations

-   **Applicant**: uses the `distinct_id` associated with the event.
-   **Session**: relies on the `properties$cbv_flow_id`. A user may have one or more sessions during a pilot period.
-   **Total Event**: When an applicant has multiple sessions, each of these unique applicant and sessions is called an total event in Mixpanel.
-   **Application submitted/successful**: the applicant finished the submission flow ending on the success page (`event == 'ApplicantSharedIncomeSummary'`). 
-   **Application start time**: uses the `timestamp` the applicant viewed the agreement page (`event == 'ApplicantViewedAgreement'`)
-   **Application duration**: the duration is then calculated from the difference between the session start time and the `timestamp` the last event was viewed.
-  **Provider sync time**: calculated using the `timestamp` between two events, `ApplicantSucceededWithLogin` and `ApplicantFinishedSync`

# Analysis

```{r}
#| label: dependencies

#dependencies to load
library(tidyverse)
library(here)
library(arrow, warn.conflicts = FALSE)
library(jsonlite, warn.conflicts = FALSE)
library(glue)
library(patchwork)
library(scales)
library(gt)
library(ggtext)
library(ggsankey) ## remotes::install_github("davidsjoberg/ggsankey")
library(glamr) ##install.packages('glamr', repos = c('https://usaid-oha-si.r-universe.dev', 'https://cloud.r-project.org'))
library(glitr) #install.packages('glitr', repos = c('https://usaid-oha-si.r-universe.dev', 'https://cloud.r-project.org'))
library(gtayblr) ## remotes::install_github("USAID-OHA-SI/gtayblr")
```

```{r}
#| label: global variables
#| echo: false
#| warning: false

#identify paths for json data for each of the three periods
mp_path <- list.files(here("app/analytics"), "mixpanel.*parquet", full.names = TRUE)

#default viz/table caption
default_caption <- "Source: Lousiana 2025 IVaaS Pilot Mixpanel Data [accessed 2025-12-15]"

#set DSAC colors
dsac_color <- c("#103D68", "#136A5D", "#6A1344", "#EFAC2F", "#63789D", "#C1C9D7", "#5A9088", "#D9E8E5", "#842F66", "#123054")
dsac_color_name <- c("navy", "teal", "cranberry", "gold", "light_navy", "pale_navy", "light_teal", "pale_teal", "light_cranberry", "dark_navy")
dsac_color <- setNames(dsac_color, dsac_color_name)
rm(dsac_color_name)
```

```{r}
#| label: import_data

df_mp <- read_parquet(mp_path)
```

```{r}
#| label: fcn_clean_events

#clean event names for viz to add space and remove repetitive "applicant" text
clean_events <- function(df){

  df |> 
    mutate(
      event_clean = event |> 
        str_replace_all("(?<!^)([A-Z])", " \\1") |> 
        str_remove("Applicant ") |> 
        str_remove(" Or Platform Item"),
        .after = event
        )
}
```

## How many users are starting but not completing the process?

To start off with, we need to understand how many applicants are starting out this process. 

Comparing how many people are completing each pilot period, in the first pilot many more applicants started the processed (i.e. viewed the agreement), but a smaller share completed it (i.e. shared their income summary). However, we do see roughly the same volume of recipients completing the process end to end.

```{r}
#| label: retention_tbl
#| output: true

 df_compl_pilot <- df_mp |> 
  filter(event %in% c("ApplicantViewedAgreement","ApplicantSharedIncomeSummary")) |> 
  clean_events() |> 
  group_by(pilot, event_clean) |> 
  summarise(
    n_distinct = n_distinct(distinct_id),
    .groups = "drop"
    ) |> 
  pivot_wider(
    names_from = event_clean,
    values_from = n_distinct
    ) |> 
  mutate(`Completion Rate` = `Shared Income Summary` / `Viewed Agreement`)

df_compl_pilot |> 
  gt() |> 
  cols_move(`Viewed Agreement`, after = pilot) |> 
  format_numeric_columns() |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  adjust_row_padding() |> 
  add_labs(
    title = "Applicant Completion Rates by Pilot",
    subtitle = "The distinct number of applicants who started and completed the process",
    caption = default_caption
  )

```

```{r}
#| label: multi_complete

df_success_diff <- df_mp |> 
  filter(
    event %in% c("ApplicantSharedIncomeSummary"),
    pilot == "Nov 2025"
    ) |> 
  group_by(pilot) |>
  summarize(
    applicants = n_distinct(distinct_id),
    sessions = n_distinct(distinct_id, cbv_flow_id),
    .groups = 'drop'
  )
```
There are a number of applicants who had multiple successful submissions (across multiple sessions, which). In the November pilot, for example, there were `{r} scales::label_comma()(df_success_diff$applicants)` distinct applicants who submitted compared with `{r} scales::label_comma()(df_success_diff$sessions)` total events.  

The table below details how many submissions were associated with an applicant.^[Since not all applicants are using tokenized link, there may in fact be more applicants successfully submitting multiple times] In the November case, there are 

```{r}
#| label: multi_complete_tbl
#| output: true

df_multi_tbl <- df_mp |> 
  filter(event %in% c("ApplicantSharedIncomeSummary")) |> 
  distinct(pilot, distinct_id, cbv_flow_id) |> 
  count(pilot, distinct_id, sort = TRUE) |> 
  count(pilot, n) |> 
  arrange(n) |> 
  group_by(pilot) |> 
  mutate(
    `Total Applicants` = sum(nn),
    `Total Events` = sum(n*nn)) |> 
  ungroup() 
  
df_multi_tbl |> 
  pivot_wider(names_from = n, values_from = nn) |> 
  gt() |>
  format_numeric_columns() |> 
  sub_missing() |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  tab_spanner(
    label = "submissions",
    columns = -c(pilot, `Total Applicants`, `Total Events`)
  ) |> 
  adjust_row_padding() |> 
  add_labs(
    title = "Some users had multiple successful submissions events" |> toupper(),
    subtitle = "the number of successful submission",
    caption = glue("Note: total sessions is the number of unique applicants and  {default_caption}")
  ) 
```

```{r}
#| label: multi_compl_deep_dive

#identify which users submitted multiple income summaries
v_multi <- df_mp |> 
  filter(pilot == "Nov 2025") |> 
  filter(event %in% c("ApplicantSharedIncomeSummary")) |> 
  distinct(pilot, distinct_id, cbv_flow_id) |> 
  group_by(distinct_id) |> 
  filter(n() > 1) |> 
  ungroup() |> 
  distinct(distinct_id) |> 
  pull()

#pull the employer information from their sync
df_multi <- df_mp |> 
  filter(
    pilot == "Nov 2025",
    event %in% c("ApplicantFinishedSync"),
    distinct_id %in% v_multi
  ) |> 
  select(pilot, distinct_id, cbv_flow_id, employer_name)

#review entries
df_mult_types <- df_multi |> 
  add_count(distinct_id, employer_name, name = "submission_count") |> 
  group_by(distinct_id) |> 
  summarise(
    unique_sessions = n_distinct(distinct_id, cbv_flow_id),
    unique_events = n(),
    unique_employers = n_distinct(employer_name),
    max_repeats = max(submission_count), 
    .groups = "drop"
  ) |> 
  mutate(
    behavior = case_when(
      unique_employers == 1 ~ "Single item repeated",
      unique_employers == unique_events ~ "All unique items",
      max_repeats > 1 ~ "Multiple items with repeats",
      TRUE ~ "Other"
    )
  ) |>
  count(behavior)

```
We should take a closer look at the repeated submissions. Some of these could be resubmissions of the same information (i.e. the applicant didn't know if the submission went through or forgot they already submitted it) or could be going back to enter in a different employeer at a differnt time. If we look at the `r sum(df_mult_types$n)` applicants with repeated submissions in the November pilot, `r df_mult_types[df_mult_types$behavior == 'Single item repeated',]$n` submitted the same employeer, `r df_mult_types[df_mult_types$behavior == 'Multiple items with repeats',]$n` submitted multiple employers with repeats, and only `r df_mult_types[df_mult_types$behavior == 'All unique items',]$n` had all unique submissions. 

### Is there a drop completion as the pilot period draws on?

If we compare weeks with in each pilot, we are seeing a similar trend of most people starting in the first week or two and then tailing off after that. While the first two pilot periods saw the second week as having the highest compeltion rate, the current pilot saw an increase in weeks 2 and then week 3 for completion rates.

```{r}
#| label: retention_viz
#| output: true

df_compl <- df_mp |> 
  filter(event %in% c("ApplicantViewedAgreement","ApplicantSharedIncomeSummary")) |> 
  clean_events() |> 
  mutate(week = timestamp |> floor_date("weeks") |> as_date()) |> 
  group_by(pilot, week, event_clean) |> 
  summarise(
    n_distinct = n_distinct(distinct_id),
    .groups = "drop"
    ) |> 
  pivot_wider(
    names_from = event_clean,
    values_from = n_distinct
    ) |> 
  mutate(completion_rate_wk = `Shared Income Summary` / `Viewed Agreement`) |> 
  group_by(pilot) |> 
  mutate(plt_wk = glue("wk{isoweek(week) - min(isoweek(week)) + 1}"), .after = pilot) |> 
  ungroup()

# add pilot average rate for viz
df_compl <- df_compl |> 
  left_join(
    df_compl_pilot |> 
      select(pilot, completion_rate_pilot = `Completion Rate`) |> 
      mutate(plt_wk = 'wk5'),
    by = join_by(pilot, plt_wk)
    )


v1 <- df_compl |> 
  ggplot(aes(plt_wk, `Viewed Agreement`)) +
  geom_col(fill = dsac_color['light_navy']) +
  facet_grid(. ~pilot, scales = "free_x", space = "free_x", switch = "y") +
  scale_y_continuous(label = label_comma()) +
  si_style_ygrid() +
  labs(
    x = NULL, y = NULL,
    subtitle = "Started Application") +
  theme(
    strip.text = element_text(hjust = .5),
    strip.placement = "outside"
    )

  v2 <- df_compl |> 
  ggplot(aes(plt_wk, completion_rate_wk)) +
  geom_col(fill = dsac_color[['light_teal']]) +
  geom_hline(
    aes(yintercept = completion_rate_pilot), na.rm = TRUE,
    color = dsac_color[['cranberry']],
    linetype = "dashed"
    ) +
  geom_label(
    aes(
      y = completion_rate_pilot, 
      label = label_percent(1)(completion_rate_pilot)), 
    na.rm = TRUE,
    family = "Source Sans 3", color = matterhorn, linewidth = 0,
    ) +
  facet_grid(. ~pilot, scales = "free_x", , space = "free_x", switch = "y") +
  scale_y_continuous(label = label_percent()) +
  labs(
    x = NULL, y = NULL,
    subtitle = "Application Completion Rate") +
  si_style_ygrid() +
  theme(
    strip.text = element_text(hjust = .5),
    strip.placement = "outside"
    )

    v1 / v2 + 
      plot_annotation(
        title = "LARGE DROP OFF IN INITIATING APPLICATION AFTER THE FIRST WEEK, BUT LARGER COMPLETION RATE IN FOLLOWING WEEKS" |> str_wrap(),
        caption = default_caption,
        theme = si_style()
      )
```

### Is there a difference in completion based on their device or how they receive the pilot url?

For the Louisana pilot, applicants were sent both text messages and emailed/mailed with a notice about the pilot. We can investigate whether there is any difference in completion rates based on how the applicants are accessing the app.

```{r}
#| label: device_origin_status

#flag if the applicant started on a tokenized or generic link
df_device_origin_status <- df_mp |> 
  mutate(
    initiation = case_when(event %in% c("ApplicantClickedCBVInvitationLink", "ApplicantClickedGenericLink") ~ str_extract(event, "CBVInvitation|ClickedGenericLink")),
    initiation = initiation |> 
      str_replace_all("(?<!^)([A-Z])", " \\1") |> 
      str_replace('C B V', "CBV")
  ) |> 
  group_by(distinct_id, cbv_flow_id) |> 
  fill(initiation, .direction = "updown") |> 
  ungroup() 
  
df_device_origin_status <- df_device_origin_status |> 
  filter(
    str_starts(distinct_id, "applicant"),
    event %in% c("ApplicantViewedAgreement", "ApplicantSharedIncomeSummary")
  ) |>  
  mutate(
    completed = event == "ApplicantSharedIncomeSummary",
    across(c(device_type, origin, initiation), ~ ifelse(is.na(.), "unknown", .)),
    device_type = ifelse(device_type %in% c("desktop", 'smartphone', 'unknown'), device_type, "other")
  ) |> 
  group_by(pilot, distinct_id, cbv_flow_id) |> 
  mutate(completed = max(completed) |> as.logical()) |> 
  ungroup() |> 
  distinct(pilot, distinct_id, cbv_flow_id, device_type, origin, completed, initiation) 

#other device types
other_devices <- unique(df_mp$device_type) |> 
  str_subset("desktop|smartphone", negate = TRUE) |> 
  paste0('s') |> 
  glue_collapse(sep = ', ', last = ", and ")

```

When comparing the device type, we can see there is a preference for applicants initiating the process on their phones. The success rate is much higher on the phones than desktop, but both success rates are rather low. The other types of devices include `{r} other_devices`.

```{r}
#| label: device_status_tbl
#| output: true

df_device_origin_status |>
  count(pilot, device = device_type, completed) |> 
  pivot_wider(
    names_from = completed, 
    values_from = n,
    values_fill = 0) |> 
  rowwise() |> 
  mutate(,
    `Viewed Agreement` = sum(`FALSE`, `TRUE`),
    `Shared Income Summary` = `TRUE`,
    `Completion Rate` = `Shared Income Summary` / `Viewed Agreement`
  ) |> 
  select(-c(`FALSE`, `TRUE`)) |> 
  arrange(pilot, desc(`Viewed Agreement`)) |> 
  gt(groupname_col = "pilot") |> 
  format_numeric_columns() |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  adjust_row_padding() |> 
  add_labs(
    title = "Most applicants start and have the highest success rate on smartphones" |> toupper(),
    subtitle = "number of distinct flows by device type",
    caption = glue("Note: Other devices include {other_devices} | {default_caption}")
  ) 
```

When looking the url origin, we see the large majority arise from SMS messages. However, the success rate is much lower than that of physical mailings.

```{r}
#| label: origin_status_tbl
#| output: true

df_device_origin_status |>
  count(pilot, origin, completed) |> 
  pivot_wider(
    names_from = completed, 
    values_from = n,
    values_fill = 0) |> 
  rowwise() |> 
  mutate(,
    `Viewed Agreement` = sum(`FALSE`, `TRUE`),
    `Shared Income Summary` = `TRUE`,
    `Completion Rate` = `Shared Income Summary` / `Viewed Agreement`
  ) |> 
  select(-c(`FALSE`, `TRUE`)) |> 
  arrange(pilot, desc(`Viewed Agreement`)) |> 
  gt(groupname_col = "pilot") |> 
  format_numeric_columns() |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  adjust_row_padding() |> 
  add_labs(
    title = "Mailed links had the highest flow completion rate" |> toupper(),
    subtitle = "number of distinct flows by url link origin",
    caption = default_caption
  ) 
```

Lastly, we can take a look at how the applicant started their session. In the November pilot, most sessions were started via a tokenized, CBV invitation but these sessions were half as successful in completing the process. This is the opposite of what occured in the August pilot.

```{r}
#| label: tokenized_status
#| output: true

df_device_origin_status |>
  count(pilot, initiation, completed) |> 
  pivot_wider(
    names_from = completed, 
    values_from = n,
    values_fill = 0) |> 
  rowwise() |> 
  mutate(,
    `Viewed Agreement` = sum(`FALSE`, `TRUE`),
    `Shared Income Summary` = `TRUE`,
    `Completion Rate` = `Shared Income Summary` / `Viewed Agreement`
  ) |> 
  select(-c(`FALSE`, `TRUE`)) |> 
  arrange(pilot, desc(`Viewed Agreement`)) |> 
  gt(groupname_col = "pilot") |> 
  format_numeric_columns() |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  adjust_row_padding() |> 
  add_labs(
    title = "Generic links see larger success rate last two pilots" |> toupper(),
    subtitle = "number of distinct flows by initiation type",
    caption = default_caption
  ) 
```

## How long does it take to complete the application?

On the client side, the goal of the pilot application is to creating something easy to complete. Ideally, applicants can complete the process in a matter of minutes. We can look at time it takes to submit to understand if it places an undue burden on applicants. 

```{r}
#| label: duration_calc

df_time <- df_mp |> 
  filter(str_starts(distinct_id, "applicant")) |> 
  mutate(
    completed = event == "ApplicantSharedIncomeSummary", 
    time_start = case_when(event == "ApplicantViewedAgreement" ~ timestamp)
    ) |> 
  group_by(pilot, distinct_id) |> 
  # group_by(pilot, distinct_id, cbv_flow_id) |> 
  mutate(
    completed = max(completed, na.rm = TRUE),
    time_end = ifelse(event == "ApplicantSharedIncomeSummary", timestamp, max(timestamp)),
    time_end = as_datetime(time_end)
    ) |>
  ungroup()

df_duration <- df_time |> 
  filter(!is.na(time_start)) |> 
  group_by(pilot, distinct_id) |> 
  summarise(
    # sessions = n_distinct(cbv_flow_id),
    completed = max(completed, na.rm = TRUE),
    time_start = max(time_start, na.rm = TRUE),
    time_end = max(time_end, na.rm = TRUE),
    .groups = "drop"
    ) |> 
  # tidylog::filter(time_start != time_end) |> 
  mutate(duration = time_end - time_start)
```

```{r}
#| label: duration_stats

df_duration_viz <- df_duration |> 
  mutate(
    completed_type = case_when(
      completed == 1 ~ 'completed',
      time_start == time_end ~ 'just clicked',
      TRUE ~ 'incomplete'
      ),
    minutes = as.numeric(duration) / 60  
      ) |> 
  group_by(pilot, completed_type) |> 
  summarise(
    n = n(),
    q25 = quantile(minutes, 0.25, na.rm = TRUE),
    median = median(minutes, na.rm = TRUE),
    mean = mean(minutes, na.rm = TRUE),
    q75 = quantile(minutes, 0.75, na.rm = TRUE),
    q90 = quantile(minutes, .9, na.rm = TRUE),
    .groups = "drop"
    )

  df_duration_stats <- df_duration_viz |> 
    filter(pilot == 'Nov 2025')
```

Looking specifically at the November pilot, of the `{r} scales::label_comma()(df_duration_stats[df_duration_stats$completed_type == 'completed',]$n)` applicants who completed the application, the median time was `{r} scales::label_number(.1)(df_duration_stats[df_duration_stats$completed_type == 'completed',]$median)` minutes, with 75% completing it within `{r} scales::label_number(.1)(df_duration_stats[df_duration_stats$completed_type == 'completed',]$q75)` minutes. The timing looks pretty good from that vantage point. However, most applicants (`{r} scales::label_comma()(df_duration_stats[df_duration_stats$completed_type != 'completed',]$n |> sum())`) are not completing the application. Of those applicants, `{r} scales::label_percent()(df_duration_stats[df_duration_stats$completed_type == 'just clicked',]$n / df_duration_stats[df_duration_stats$completed_type != 'completed',]$n |> sum())` are clicking the link and not proceeding beyond viewing the initial agreement page. When looking at incomplete applications excluding those that only viewed the agreement page, the median applicant spends `{r} scales::label_number(.1)(df_duration_stats[df_duration_stats$completed_type == 'incomplete',]$median)` minutes on the application before they stop, with 75% aborting after only `{r} scales::label_number(.1)(df_duration_stats[df_duration_stats$completed_type == 'incomplete',]$q75)` minutes. 

```{r}
#| label: viz_duration
#| output: true
df_duration_viz |> 
  mutate(
    fill_color = 
    case_match(completed_type,
      'completed' ~ dsac_color['navy'],
      'incomplete' ~ dsac_color['cranberry'],
      'just clicked' ~ dsac_color['cranberry']
      ),
    completed_type = glue('{completed_type} (n = {label_comma()(n)})')) |> 
  ggplot(aes(y = fct_rev(completed_type), group = completed_type, color = fill_color)) +
  geom_linerange(aes(xmin = q25, xmax = q75)) +
  geom_point(aes(median), size = 4) +
  geom_text(
    aes(median, label = label_number(accuracy = .1, suffix = 'm')(median)), 
    family = "Source Sans 3", vjust = -1) +
  facet_grid(pilot ~. , switch = "y", scales = "free_y") +
  scale_x_continuous(labels = label_number( suffix = 'm'), position = "top") +
  scale_color_identity() +
  labs(
    x = NULL, y = NULL,
    title = glue("{toupper(df_duration_stats$pilot[1])} USERS NOT COMPLETING THE APPLICATION END AFTER ABOUT {label_number(.1)(df_duration_stats[df_duration_stats$completed_type == 'incomplete',]$median)} MINUTES"),
    subtitle = 
      "displaying the median session **minutes** and IQR",
    caption = glue("Note: Applicants falling into 'just clicked' count represent those who didn't have an event beyond viewing the agreement 
    default_caption") 
      ) +
  si_style() +
  theme(
    plot.subtitle = element_markdown(),
    strip.placement = "outside",
    strip.text = element_text(hjust = .5),
    panel.spacing=unit(0.5, "lines")
    )

```

### How long does the income data syncing take?

Syncing the data once the employer is chosen can take a bit of time to occur. The longer it takes, we may be more likely to see applicants drop off.  

```{r}
#| label: data_sync

df_sync_init <- df_mp |> 
  filter(
    event %in% c("ApplicantAttemptedLogin","ApplicantSucceededWithLogin", "ApplicantFinishedSync"),
    ) |>
  distinct(distinct_id, cbv_flow_id, timestamp, event, pilot, provider) |> 
  arrange(distinct_id, cbv_flow_id, timestamp) |> 
  group_by(distinct_id, cbv_flow_id, event) |>
  mutate(attempt_n = row_number()) |> 
  ungroup() |>
  pivot_wider(
    names_from = event,
    values_from = timestamp
    ) |> 
  mutate(sync_time = ApplicantFinishedSync - ApplicantSucceededWithLogin)

df_sync <- df_sync_init |> 
  tidylog::filter(
    !is.na(sync_time), 
    sync_time >= 0
    ) 

df_sync_viz <- df_sync |> 
  group_by(pilot, provider) |> 
  summarise(
    n = n(),
    min = min(sync_time, na.rm = TRUE), 
    q25 = quantile(sync_time, 0.25, na.rm = TRUE),
    median = median(sync_time, na.rm = TRUE),
    q75 = quantile(sync_time, 0.75, na.rm = TRUE),
    max = max(sync_time, na.rm = TRUE),
    .groups = "drop"
    ) 

```
```{r}
#| label: long_sync

lng_run <- 180

v_lng_run_shr <- df_sync |> 
  count(sync_time > lng_run) |> 
  mutate(share = n / sum(n)) |> 
  filter(`sync_time > lng_run` == TRUE) |> 
  mutate(label = label_percent(1)(share)) |> 
  pull()

```
Overall, we are looking at a median sync time of `{r} median(df_sync$sync_time, na.rm = TRUE)` seconds, with 75% of events seeing it take under `{r} quantile(df_sync$sync_time, .75, na.rm = TRUE)` seconds. Of the `{r} scales::label_comma()(nrow(df_sync))` successful data syncs, `{r} v_lng_run_shr` take longer than `{r} lng_run` seconds to sync. 

We can see how this places our when comparing different payroll aggregators used, Argyle and Pinwheel. Each pilot we can see there is a signficant gap between the time range it takes to sync with Pinwheel versus Argyle. 

```{r}
#| label: data_sync_tbl
#| eval: false

df_sync_viz |> 
  gt(groupname_col = "pilot") |> 
  fmt_number(columns = everything(), decimals = 0) |> 
  fmt_duration(columns = -n,
    input_units = "seconds"
    ) |> 
  adjust_row_padding() |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  add_labs(
    caption = default_caption
  )

```

```{r}
#| label: data_sync_viz
#| output: true
df_sync_viz |> 
  mutate(
    fill_color = ifelse(provider == "Argyle", dsac_color['light_navy'], dsac_color['light_teal']),
    provider = glue('{provider} (n = {label_comma()(n)})')) |> 
  ggplot(aes(y = fct_rev(provider), group = provider, color = fill_color)) +
  geom_linerange(aes(xmin = q25, xmax = q75)) +
  geom_point(aes(median), size = 4) +
  geom_text(
    aes(median, label = label_timespan(accuracy = 1)(median)), 
    family = "Source Sans 3", vjust = -1) +
  facet_grid(pilot ~. , switch = "y", scales = "free_y") +
  scale_x_continuous(label = label_timespan(), position = "top") +
  scale_color_identity() +
  labs(
    x = NULL, y = NULL,
    title = "Slightly shorter Pinwheel median sync, but a smaller sample size" |> toupper(),
    subtitle = 
      "displaying the median session **seconds** against the IQR",
    caption = default_caption 
      ) +
  si_style_xgrid() +
  theme(
    strip.placement = "outside",
    strip.text = element_text(hjust = .5),
    plot.subtitle = element_markdown(),
    panel.spacing=unit(0.5, "lines")
    )
```

Sticking with the provider comparision, we can look at the distribtion of sync times. By bucketing them, we can see that most events have a sync time between 30 seconds and a minute and about 95% are under the 3 minute mark. 

```{r}
#| label: data_sync_bucketed_viz
#| output: true
df_sync_bucketed <- df_sync |> 
  mutate(
    sync_bucket = 
      case_when(
        sync_time <= 30 ~ "<=30s",
        sync_time <= 60 ~ ">30s - 1m",
        sync_time <= 180 ~ ">1m - 3m",
        sync_time <= 300 ~ ">3m - 5m",
        sync_time <= 600 ~ ">5m - 10m",
        TRUE ~ ">10m"
        ),
      sync_bucket = factor(sync_bucket, c("<=30s", ">30s - 1m", ">1m - 3m", ">3m - 5m", ">5m - 10m", ">10m"))
  ) |> 
  count(pilot, sync_bucket) |> 
  arrange(pilot, sync_bucket) |> 
  group_by(pilot) |> 
  mutate(
    share = n / sum(n),
    cum_share = cumsum(n) / sum(n)
    ) |> 
  ungroup()

  df_sync_bucketed |> 
    ggplot(aes(n, fct_rev(sync_bucket), fill = sync_bucket)) +
    geom_col() + 
    geom_text(
      aes(label = label_percent(1)(share)),
      family = "Source Sans 3", hjust = -.1, color = matterhorn, 
      ) + 
    facet_wrap(~pilot) +
    coord_cartesian(clip = "off") + 
    scale_fill_manual(values = unname(c(dsac_color['teal'], dsac_color['dark_navy'], dsac_color['navy'], dsac_color['light_navy'], dsac_color['light_cranberry'], dsac_color['cranberry']))) +
    labs(
      x = NULL, y = NULL,
      subtitle = "income sync time with provider by number of sessions",
      caption = default_caption) +
    si_style_xgrid() +
    theme(legend.position = "none")    
```

The next visual look at the same data, but plots each of the event individually, allowing us to see some of the larger outliers and where the specific times fall compared within the broader buckets. The x-axis has been truncated to 20 minutes to see the distrbution, plotting the `r dplyr::filter(df_sync, sync_time > 1200) |> nrow()` outliers on the 20 minute mark. Both providers saw three events with sync times over 20 minutes in the November pilot, but the median time went down from August.  

```{r}
#| label: data_sync_distro_viz
#| output: true 
 
 df_sync |>
    mutate(
      sync_bucket = 
        case_when(
          sync_time <= 30 ~ "<=30s",
          sync_time <= 60 ~ ">30s - 1m",
          sync_time <= 180 ~ ">1m - 3m",
          sync_time <= 300 ~ ">3m - 5m",
          sync_time <= 600 ~ ">5m - 10m",
          TRUE ~ ">10m"
          ),
      sync_bucket = factor(sync_bucket, c("<=30s", ">30s - 1m", ">1m - 3m", ">3m - 5m", ">5m - 10m", ">10m"))) |> 
    ggplot(aes(sync_time, fct_rev(pilot), color = sync_bucket)) +
    geom_point(position = position_jitter(height = 0.3, seed = 42), alpha = 0.4) + 
    stat_summary(fun = "median", color = dsac_color['gold'], shape = 23, linewidth = 1.1, na.rm = TRUE) + 
    facet_grid(provider ~. , switch = "y", scales = "free_y") + 
    scale_x_continuous(
      label = label_number(.1, scale = 1/60, suffix = "m"), limits = c(0, 1200),
      breaks = seq(0, 1200, 150),
      oob=scales::squish, position = "top") +
    scale_color_manual(values = unname(c(dsac_color['teal'], dsac_color['dark_navy'], dsac_color['navy'], dsac_color['light_navy'], dsac_color['light_cranberry'], dsac_color['cranberry']))) +
    labs(
      x = NULL, y = NULL, 
      subtitle = "income sync time with provider | each point represents a session | gold diamonds represent the median",
      caption = glue("Note: Sync time capped at 20 minutes
      {default_caption}")) +
    si_style_xgrid() +
    theme(
      strip.text = element_text(hjust = .5),
      strip.placement = "outside",
      legend.position = "none"
      )
```
### When there was a provider outage, was there any change in processing times?

During the November pilot, Argyle had an outage between November 19-20. Looking by day, we can see that Monday, November 20th had a dip in the number of Argyle events compared witht he prior day and Pinhweel saw an increase on both November 19th and 20th (though certainly not enough to offset the dip). During the first day of the outage, the success rate of logging for both providers dropped precipitously, but rebounded on November 20th.

```{r}
#| label: sync_outage
#| output: true

df_outage_viz_rt <- df_sync_init |> 
  filter(
    pilot == "Nov 2025",
    !is.na(ApplicantAttemptedLogin),
    ) |> 
  mutate(
    date = as_date(ApplicantAttemptedLogin),
    succeeded = !is.na(ApplicantFinishedSync)
  ) |> 
  group_by(date, provider, distinct_id, cbv_flow_id) |> 
  summarize(succeeded = max(succeeded, na.rm = TRUE), .groups = "drop") |> 
  group_by(date, provider) |> 
  summarize(
    attempted = n_distinct(distinct_id, cbv_flow_id),
    succeeded = sum(succeeded, na.rm = TRUE),
    .groups = "drop"
  ) |> 
  mutate(
    success_rate = succeeded/attempted,
    fillcolor = ifelse(provider == "Argyle", dsac_color['light_navy'], dsac_color['light_teal']),
    provider_x = ifelse(provider == "Argyle", -.08, -.05),
    date_fmt = case_when(
      date %in% c('2025-11-17', '2025-12-01') ~ format(date, format = "%b %d"),
      month(date) == 11 ~ format(date, format = "%d"),
      month(date) == 12 ~ format(date, format = " %d"),
      ) |> fct_inorder()
    )

df_outage_viz_rt |> 
  ggplot(aes(y = fct_rev(date_fmt), color = fillcolor, , fill = fillcolor, group = date_fmt)) +
  geom_line(aes(success_rate), color = "#909090") + 
  geom_point(aes(success_rate), size = 3, shape = 21, color = "white") +
  geom_point(aes(provider_x, size = attempted), shape = 15) +
  geom_text(
    aes(provider_x - .02, label = attempted),
    data = df_outage_viz_rt |> filter(provider == "Argyle"), 
    family = "Source Sans 3", hjust = 1, color = "#505050") + 
  geom_text(
    aes(provider_x + .04, label = attempted),
    data = df_outage_viz_rt |> filter(provider != "Argyle"), 
    family = "Source Sans 3", hjust = 1, color = "#505050") + 
  annotate(
    geom = 'rect',
    ymin = 29.5, ymax = 31.5,
    # ymin = '2025-11-19', ymax = '2025-11-19',
    xmin = -Inf, xmax = Inf,
    alpha = .3, fill = "#909090"
    ) +
  scale_x_continuous(
    labels = label_percent(), 
    breaks = seq(0, 1, .2), 
    minor_breaks = seq(0, 1, .1),
    position = "top") + 
  scale_color_identity(aesthetics = c('fill', 'color')) +
  scale_size(guide = "none") +
  labs(
    x = NULL, y = NULL,
    title = "MOST DAYS APPLICANTS ACCESSING ARGYLE SAW A HIGHER SUCCESSFUL LOGIN RATE",
    subtitle = glue("daily <span style = color:{dsac_color['light_navy']};>**Argyle**</span>/<span style = color:{dsac_color['light_teal']};>**Pinwheel**</span> user flow attempts to login [left] and  successful rates [right]"),
    caption = glue('Note: Argyle outage Nov 19-20
    {default_caption}')
  ) + 
  si_style_xgrid() +
  theme(plot.subtitle = element_markdown())

#si_save(here("app/analytics/success_rate.png"), height = 7)
```

During those two Argyle outage days, Pinwheel had the two highest median data sync times for the fives weeks of the pilot. 

```{r}
#| label: sync_outage2
#| output: true
df_outage_viz <- df_sync |> 
  filter(
    pilot == "Nov 2025",
    !is.na(ApplicantAttemptedLogin)
    ) |> 
  mutate(date = ApplicantAttemptedLogin |> as_date()) |> 
  group_by(date, provider) |> 
  summarize(
    n = n_distinct(distinct_id, cbv_flow_id),
    q25 = quantile(sync_time, 0.25, na.rm = TRUE),
    median = median(sync_time, na.rm = TRUE),
    q75 = quantile(sync_time, 0.75, na.rm = TRUE),
    .groups = "drop"
    ) |> 
  mutate(
    fillcolor = ifelse(provider == "Argyle", dsac_color['light_navy'], dsac_color['light_teal']),
    provider_x = ifelse(provider == "Argyle", -35, -20),
    date_fmt = case_when(
      date %in% c('2025-11-17', '2025-12-01') ~ format(date, format = "%b %d"),
      month(date) == 11 ~ format(date, format = "%d"),
      month(date) == 12 ~ format(date, format = " %d"),
      ) |> fct_inorder()
  )

df_outage_provider_median <- df_sync |> 
  filter(
    pilot == "Nov 2025",
    !is.na(ApplicantAttemptedLogin)
    ) |> 
  mutate(date = ApplicantAttemptedLogin |> as_date()) |> 
  group_by(provider) |> 
  summarize(median_provider = median(sync_time, na.rm = TRUE) |> as.numeric()) |> 
  ungroup() |> 
  pivot_wider(names_from = provider, values_from = median_provider)

df_outage_viz |> 
  ggplot(aes(y = fct_rev(date_fmt), color = fillcolor, group = provider)) +
  geom_linerange(aes(xmin = q25, xmax = q75), position = position_dodge(.9,  orientation = "y")) +
  geom_point(aes(provider_x, size = n), shape = 15) + 
  geom_text(
    aes(provider_x -10, label = n),
    data = df_outage_viz |> filter(provider == "Argyle"), 
    family = "Source Sans 3", hjust = 1, color = "#505050") + 
  geom_text(
    aes(provider_x + 14, label = n),
    data = df_outage_viz |> filter(provider != "Argyle"), 
    family = "Source Sans 3", hjust = 1, color = "#505050") + 
  geom_point(aes(median), position = position_dodge(.9, orientation = "y")) +
  annotate(
    geom = 'rect',
    ymin = 29.5, ymax = 31.5,
    xmin = -Inf, xmax = Inf,
    alpha = .3, fill = "#909090"
    ) + 
  scale_x_continuous(
    limit = c(-45,300), 
    label = label_number(1, scale = 1/60, suffix = "m"),
    breaks = seq(0, 300, 60),
    oob = scales::squish, 
    position = "top") + 
  scale_color_identity() +
  scale_size(guide = "none") +
  labs(
    x = NULL, y = NULL,
    title = glue("DESPITE SOME LARGE OUTLIERS AND LESS FLOWS, PINWHEEL'S MEDIAN SYNC TIME ({df_outage_provider_median$Pinwheel}s) IS ONLY A FEW SECONDS SLOWER THAN ARGYLE ({df_outage_provider_median$Argyle}s)") |> str_wrap(),
    subtitle = glue("successful daily <span style = color:{dsac_color['light_navy']};>**Argyle**</span>/<span style = color:{dsac_color['light_teal']};>**Pinwheel**</span> user flow syncs [left] and their duration, **minutes** [median and IQR]"),
    caption = glue('Note: x axis truncated to 5 minutes; Argyle outage Nov 19-20 
    {default_caption}')
  ) + 
  si_style_xgrid() +
  theme(plot.subtitle = element_markdown())


#si_save(here("app/analytics/sync_times.png"), height = 7)
```

## Where are people dropping off?

To get a sense of where applicants are dropping off, we can look at some key points/pages to see whether they reached that step. 

```{r}
#| label: event_steps

v_steps <- c(
  "ApplicantViewedAgreement",
  "ApplicantAgreed",
  "ApplicantSelectedEmployerOrPlatformItem",
  "ApplicantAttemptedLogin",
  "ApplicantSucceededWithLogin",
  "ApplicantViewedPaymentDetails",
  "ApplicantSharedIncomeSummary"
  )
```

```{r}
#| label: event_table
#| output: true

df_ret <- df_mp |>
  filter(event %in% v_steps) |> 
  clean_events() |> 
  select(pilot, distinct_id, event_clean) |> 
  distinct(pilot, distinct_id, event_clean) |> 
  count(pilot, event_clean, sort = TRUE, name = "views") |> 
  mutate(
    share_lag = views / lag(views),
    share_cumlative = views / max(views),
    share_cumlative = ifelse(event_clean == "Viewed Agreement", NA, share_cumlative)
      )

df_ret |>
  gt(groupname_col = "pilot") |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  adjust_row_padding() |> 
  format_numeric_columns() |> 
  sub_missing()

```

Right off the bat, we can see that off the `{r} scales::label_comma()(df_ret[df_ret$event_clean == "Viewed Agreement",]$views)` distinct users who started the application, only `{r} scales::label_percent(1)(df_ret[df_ret$event_clean == "Agreed",]$share_cum)` agreed to terms to move on, and only `{r} scales::label_percent(1)(df_ret[df_ret$event_clean == "Shared Income Summary",]$share_cum)` actually made it to completion, submitting their pay information. 

```{r}
#| label: event_journey
#| output: true

df_journey <- df_mp |> 
  filter(event %in% v_steps) |> 
  select(distinct_id, event) |> 
  distinct(distinct_id, event) |> 
  mutate(status = "reached") |> 
  complete(distinct_id, event) |> 
  mutate(event = factor(event, v_steps)) |> 
  arrange(distinct_id, event) |> 
  group_by(distinct_id) |> 
  mutate(
    step_order = row_number(),
    step_event =  case_when(
      status == "reached" ~ as.character(event), 
      is.na(status) & lag(status) == "reached" ~ "dropped"
      # TRUE ~ "dropped"
    )) |>
  ungroup() %>%
  select(-event, -status) |> 
  filter(!is.na(step_event)) |> 
  mutate(step_event = factor(step_event, c("dropped", v_steps))) |> 
  pivot_wider(
    id_cols = distinct_id,
    names_from = step_order,
    values_from = step_event,
    names_prefix = "step_"
  )


# Convert to long format for ggsankey

sankey_long <- df_journey %>%
  make_long(step_1, step_2, step_3, step_4, step_5, step_6, step_7) |> 
  filter(!is.na(node)) |> 
  mutate(
    node = factor(node, c("dropped",v_steps)),
    next_node = factor(next_node, c("dropped",v_steps)),
    fill_color = ifelse(node == "dropped", dsac_color[['gold']], dsac_color[['teal']])
   )

sankey_long |> 
  ggplot(
    aes(x = x, 
        next_x = next_x, 
        node = node, 
        next_node = next_node,
        fill = fill_color)) +
  geom_sankey(flow.alpha = 0.6, node.color = "gray30", width = 0.1, na.rm = TRUE) +
  # geom_sankey_label(size = 3, color = "white", fill = NA) +
  scale_x_discrete(labels = v_steps) +
  scale_fill_identity() + 
  labs(x = NULL, y = NULL) +
  si_style_nolines() + 
  theme(axis.text = element_blank()) 
```

## Are users accessing the documentation (help or FAQ) before dropping off?

The prior section gave use a sense of where users were dropping off. It may be useful to see if users are accessing the documentation before they abort the application. Looking at the data, we can see that on average, those who completed the application had slight more "help actions" than those who did not. This of course is affected by the fact that those who continued saw more pages than those who did not or that using the help more they were more likely to find what they needed to continue onward. 

```{r}
#| label: help_events
v_help_events <- c(
  "ApplicantOpenedHelpModal",
  "ApplicantViewedHelpText", 
  "ApplicantViewedHelpTopic", 
  "ApplicantManuallySwitchedLanguage")
```

```{r}
#| label: help_summary
#| output: true

df_sessions <- df_time |> 
  mutate(help = event %in% v_help_events) |> 
  group_by(pilot, distinct_id) |>
  summarise(
    sessions = n_distinct(cbv_flow_id),
    completed = max(completed, na.rm = TRUE),
    help_actions = sum(help, na.rm = TRUE),
    .groups = "drop"
    ) |> 
  group_by(pilot, completed) |> 
  summarise(
    n_users = n_distinct(distinct_id),
    mean_sessions = mean(sessions, na.rm = TRUE),
    mean_help_actions = mean(help_actions, na.rm = TRUE),
    .groups = "drop"
  ) |> 
  mutate(completed = as.logical(completed))

df_sessions |> 
  gt() |> 
  fmt_number(columns = n_users, decimals = 0) |> 
  fmt_number(columns = starts_with('mean'), decimals = 1) |> 
  si_gt_base(header_fill = dsac_color['light_teal']) |> 
  adjust_row_padding() 
  # add_labs(
  #   title = "Completion Rates by Pilot"
  # )

```

We can investigate this further, looking at the total help views by page, comparing whether the user continued on past that page or ended there. We can see that most of the agreement page are on the agreement. There is significantly more usage of the help^1[In this particular case, we are looking at the number of times the help or FAQ was access, so we can have multiple help access points by user on the same page] than those who used help on that page but continued on to the next page. 

```{r}
#| label: help_viz
#| output: true

v_page_order <- tibble(event = c("LandingPage", v_steps)) |> clean_events() |> pull()

df_help <- df_time |> 
  left_join(
    tibble(
      event_order = 1:length(v_steps), 
      event = v_steps
      ) |> 
    clean_events() |> 
    rename(page = event_clean),
    by = "event"
  )|>
  group_by(distinct_id, cbv_flow_id) |> 
  fill(page, .direction = "up") |> 
  fill(event_order, .direction = "up") |> 
  mutate(
    event_order = ifelse(is.na(event_order), 0, event_order),
    page = ifelse(is.na(page), "Landing Page", page)
    ) |> 
  mutate(
    page = factor(page, v_page_order),
    last_page = event_order == max(event_order, na.rm = TRUE),
    accessed_help = event %in% v_help_events
      ) |> 
  ungroup() |> 
  group_by(distinct_id, cbv_flow_id, page, last_page) |> 
  mutate(accessed_help = max(accessed_help, na.rm = TRUE)) |> 
  ungroup()


df_help_viz <- df_help  |> 
  group_by(page, last_page) |> 
  summarise(
    n_users = n_distinct(distinct_id),
    sessions = n_distinct(distinct_id, cbv_flow_id),
    accessed_help = sum(accessed_help, na.rm = TRUE),
    .groups = "drop"
  ) |> 
  mutate(
    fill_color = ifelse(last_page == TRUE, dsac_color['teal'], dsac_color['light_navy']),
    last_page_lab = ifelse(last_page == TRUE, "Last Page", "Continued On")
    )

df_help_viz |> 
  ggplot(aes(accessed_help, fct_rev(page), fill = fill_color)) +
  geom_col() +
  facet_wrap(~fct_rev(last_page_lab)) +
  labs(x = NULL, y = NULL) +
  scale_fill_identity() + 
  scale_x_continuous(label = comma_format()) +
  si_style_xgrid()

```


## How many users are not finding their employer in the search?

One reason for retention to drop off could be from applicant not able to find their employers or platforms in in the search.
-
```{r}
#| label: search
#| output: true

df_search <- df_mp |> 
  mutate(
    picked = event == "ApplicantClickedPopularAppEmployers",
    searches = event == "ApplicantSearchedForEmployer",
    missingresults = event == "ApplicantAccessedMissingResultsPage"
    ) |> 
  group_by(pilot) |> 
  summarise(
    n_users = n_distinct(distinct_id),
    sessions = n_distinct(distinct_id, cbv_flow_id),
    picked = sum(picked, na.rm = TRUE),
    searches = sum(searches, na.rm = TRUE),
    missingresults = sum(missingresults, na.rm = TRUE),
    .groups = "drop"
    )

df_search |> 
  gt() |> 
  adjust_row_padding() |> 
  si_gt_base() |> 
  format_numeric_columns()
```

## Are the popular app employers the right ones (i.e. do there appear to be employeers searched more frequently than any that appear in the popular links)

```{r}
# df_employers <- df_mp |> 
#   filter(event== "ApplicantFinishedSync") |> 
#   mutate(
#         employer = map_chr(
#           properties,
#           ~ pluck(.x, "employment_employer_name", .default = NA_character_)
#           )
#         )

# df_employers |> 
#   filter(!is.na(employer)) |> 
#   count(employer, sort = TRUE)
```
